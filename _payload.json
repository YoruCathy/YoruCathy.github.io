[{"data":1,"prerenderedAt":376},["Reactive",2],{"content-query-1DxZ1vYQk5":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"hideTitle":8,"disableFancyImage":8,"body":9,"_type":371,"_id":372,"_source":373,"_file":374,"_extension":375},"/","",false,"Home",true,{"type":10,"children":11,"toc":363},"root",[12,17,25,51,65,79,85,110,132,138,148,156,164,172,179,198,207,215,224,233,239,247,270,278,316,322,333,343,353],{"type":13,"tag":14,"props":15,"children":16},"element","IndexHeader",{},[],{"type":13,"tag":18,"props":19,"children":21},"h2",{"id":20},"about-me",[22],{"type":23,"value":24},"text","üê± About Me",{"type":13,"tag":26,"props":27,"children":28},"p",{},[29,31,40,42,49],{"type":23,"value":30},"My name is Ruolin Ye. I am a second-year Ph.D. student at Cornell University supervised by ",{"type":13,"tag":32,"props":33,"children":37},"a",{"href":34,"rel":35},"https://sites.google.com/site/tapomayukh",[36],"nofollow",[38],{"type":23,"value":39},"Prof. Tapomayukh Bhattacharjee",{"type":23,"value":41},". I worked with ",{"type":13,"tag":32,"props":43,"children":46},{"href":44,"rel":45},"https://www.mvig.org/",[36],[47],{"type":23,"value":48},"Prof. Cewu Lu",{"type":23,"value":50},", in MVIG Lab during my undergrad at Shanghai Jiao Tong University.",{"type":13,"tag":26,"props":52,"children":53},{},[54,56,63],{"type":23,"value":55},"My broad research interest is robotic caregiving, and I am especially interested in the task of transferring. I study how to coordinate multiple instrumented assistive devices to complete this task. I am also interested in simulation. I am leading the ",{"type":13,"tag":32,"props":57,"children":60},{"href":58,"rel":59},"https://emprise.cs.cornell.edu/rcareworld/",[36],[61],{"type":23,"value":62},"RCareWorld",{"type":23,"value":64}," simulation project.",{"type":13,"tag":26,"props":66,"children":67},{},[68,70,77],{"type":23,"value":69},"In my spare time, I volunteer at ",{"type":13,"tag":32,"props":71,"children":74},{"href":72,"rel":73},"https://www.wonderfulwheelchairs.info/home",[36],[75],{"type":23,"value":76},"Wonderful Wheelchairs",{"type":23,"value":78},", a local non-profit organization that repairs and sells assistive devices to people with a low cost. I enjoy horseback riding, sketching, making cocktails, and spending time with my cat.",{"type":13,"tag":18,"props":80,"children":82},{"id":81},"experiences",[83],{"type":23,"value":84},"ü•∑ Experiences",{"type":13,"tag":86,"props":87,"children":89},"ExperienceRow",{"icon":88},"cornell.png",[90],{"type":13,"tag":26,"props":91,"children":92},{},[93,99,103,105,108],{"type":13,"tag":94,"props":95,"children":96},"strong",{},[97],{"type":23,"value":98},"Cornell University, Ithaca, NY",{"type":13,"tag":100,"props":101,"children":102},"br",{},[],{"type":23,"value":104},"\nPh.D. Student in Computer Science",{"type":13,"tag":100,"props":106,"children":107},{},[],{"type":23,"value":109},"\nAug 2022 - Present",{"type":13,"tag":86,"props":111,"children":113},{"icon":112},"sjtu.png",[114],{"type":13,"tag":26,"props":115,"children":116},{},[117,122,125,127,130],{"type":13,"tag":94,"props":118,"children":119},{},[120],{"type":23,"value":121},"Shanghai Jiao Tong University, Shanghai, China",{"type":13,"tag":100,"props":123,"children":124},{},[],{"type":23,"value":126},"\nBachelor of Engineering in Information Engineering",{"type":13,"tag":100,"props":128,"children":129},{},[],{"type":23,"value":131},"\nSep 2018 - Aug 2022",{"type":13,"tag":18,"props":133,"children":135},{"id":134},"publications",[136],{"type":23,"value":137},"üìÑ Publications",{"type":13,"tag":139,"props":140,"children":147},"PublicationRow",{":artifactLinks":141,":authors":142,":venue":143,"thumbnail":144,"title":145,"type":146},"{\"Paper\":\"https://arxiv.org/abs/2410.10017\",\"Website\":\"https://emprise.cs.cornell.edu/repeat/\"}","[\"Nayoung Ha*\",\"Ruolin Ye*\",\"Ziang Liu\",\"Shubhangi Sinha\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2024,\"name\":\"International Conference on Intelligent Robots and Systems\"}","repeat.png","REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding","conference",[],{"type":13,"tag":139,"props":149,"children":155},{":artifactLinks":150,":authors":151,":venue":152,"thumbnail":153,"title":154,"type":146},"{\"Paper\":\"https://ieeexplore.ieee.org/abstract/document/10610050\",\"Website\":\"https://emprise.cs.cornell.edu/morpheus/\"}","[\"Ruolin Ye\",\"Yifei Hu\",\"Yuhan (Anjelica) Bian\",\"Luke Kulm\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"ICRA\",\"year\":2024,\"name\":\"IEEE International Conference on Robotics and Automation\"}","peeling.png","MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop",[],{"type":13,"tag":139,"props":157,"children":163},{":artifactLinks":158,":authors":159,":venue":160,"thumbnail":161,"title":162,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu\",\"Wenxin Du\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV (Oral)\",\"year\":2023,\"name\":\"International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",[],{"type":13,"tag":139,"props":165,"children":171},{":artifactLinks":166,":authors":167,":venue":168,"thumbnail":169,"title":170,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"Website\":\"https://sites.google.com/view/vtaco/\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vtaco\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu\"]","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"The IEEE/CVF Conference on Computer Vision and Pattern Recognition\"}","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction",[],{"type":13,"tag":139,"props":173,"children":178},{":artifactLinks":174,":authors":175,":venue":168,"thumbnail":176,"title":177,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"Website\":\"https://garment-tracking.robotflow.ai/\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vr-folding\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\"}","[\"Han Xue*\",\"Wenqiang Xu*\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","garmentTracking.png","GarmentTracking: Category-Level Garment Pose Tracking",[],{"type":13,"tag":139,"props":180,"children":186},{":artifactLinks":181,":authors":182,":venue":183,"thumbnail":184,"title":185,"type":146},"{\"Paper\":\"https://drive.google.com/file/d/1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28/view\",\"Code\":\"https://github.com/empriselab/RCareWorld\",\"Website\":\"https://emprise.cs.cornell.edu/rcareworld/\",\"Presentation\":\"https://www.youtube.com/watch?v=mNy1cloWrP0\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Haoyuan Fu\",\"Rajat Kumar Jenamani\",\"Vy Nguyen\",\"Cewu Lu\",\"Katherine Dimitropoulou\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2022,\"name\":\"IEEE/RSJ International Conference on Intelligent Robots and Systems\"}","rcareworld.png","RCareWorld: A Human-centric Simulation World for Caregiving Robots",[187],{"type":13,"tag":26,"props":188,"children":189},{},[190],{"type":13,"tag":191,"props":192,"children":195},"span",{"className":193},[194],"text-red-700",[196],{"type":23,"value":197},"Best RoboCup paper (Winner). Best paper/best student paper (Finalist).",{"type":13,"tag":139,"props":199,"children":206},{":artifactLinks":200,":authors":201,":venue":202,"thumbnail":203,"title":204,"type":205},"{\"Website\":\"https://sites.google.com/view/rfuniverse\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Zhenjun Yu\",\"Jieyi Zhang\",\"Yongxi Huang\",\"Cewu Lu\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics Science and Systems\"}","rfuniverse.png","RFUniverse: A Multiphysics Simulation Platform for Embodied AI","insubmission",[],{"type":13,"tag":139,"props":208,"children":214},{":artifactLinks":209,":authors":210,":venue":211,"thumbnail":212,"title":213,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf\",\"Website\":\"https://sites.google.com/view/handover-h2o/home\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Zhendong Xue\",\"Tutian Tang\",\"Yanfeng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV\",\"year\":2021,\"name\":\"International Conference on Computer Vision\"}","h2o.png","H2O: A Benchmark for Visual Human-human Object Handover Analysis",[],{"type":13,"tag":139,"props":216,"children":223},{":artifactLinks":217,":authors":218,":venue":219,"thumbnail":220,"title":221,"type":222},"{\"Paper\":\"https://arxiv.org/pdf/2012.01050.pdf\",\"Code\":\"https://github.com/YoruCathy/USDSeg-FCOS\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Lixin Yang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2020,\"name\":\"Preprint\"}","usd-seg.png","Learning Universal Shape Dictionary for Realtime Instance Segmentation","preprint",[],{"type":13,"tag":139,"props":225,"children":232},{":artifactLinks":226,":authors":227,":venue":228,"thumbnail":229,"title":230,"type":222,":hideBottomBorder":231},"{\"Paper\":\"https://arxiv.org/pdf/2106.03382.pdf\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2021,\"name\":\"Preprint\"}","contour.png","ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass","true",[],{"type":13,"tag":18,"props":234,"children":236},{"id":235},"Ô∏è-services-and-awards",[237],{"type":23,"value":238},"‚ù§Ô∏è Services and Awards",{"type":13,"tag":26,"props":240,"children":241},{},[242],{"type":13,"tag":94,"props":243,"children":244},{},[245],{"type":23,"value":246},"Academic services",{"type":13,"tag":248,"props":249,"children":250},"ul",{},[251],{"type":13,"tag":252,"props":253,"children":254},"li",{},[255,257],{"type":23,"value":256},"Reviewer\n",{"type":13,"tag":248,"props":258,"children":259},{},[260,265],{"type":13,"tag":252,"props":261,"children":262},{},[263],{"type":23,"value":264},"Conferences: ICCV 2023, CVPR 2022&2023, ECCV 2022, IROS 2022-2024, ICRA 2023-2024, HRI 2025",{"type":13,"tag":252,"props":266,"children":267},{},[268],{"type":23,"value":269},"Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics, T-RO",{"type":13,"tag":26,"props":271,"children":272},{},[273],{"type":13,"tag":94,"props":274,"children":275},{},[276],{"type":23,"value":277},"Awards",{"type":13,"tag":248,"props":279,"children":280},{},[281,286,291,296,301,306,311],{"type":13,"tag":252,"props":282,"children":283},{},[284],{"type":23,"value":285},"Outstading teaching assistant, Cornell 2024",{"type":13,"tag":252,"props":287,"children":288},{},[289],{"type":23,"value":290},"IROS-SDC Travel Award, IROS 2022",{"type":13,"tag":252,"props":292,"children":293},{},[294],{"type":23,"value":295},"RoboCup Best Paper Award, IROS 2022",{"type":13,"tag":252,"props":297,"children":298},{},[299],{"type":23,"value":300},"Best Paper/Student Paper Finalist, IROS 2022",{"type":13,"tag":252,"props":302,"children":303},{},[304],{"type":23,"value":305},"Bosch AIoT Scholarship, 2022",{"type":13,"tag":252,"props":307,"children":308},{},[309],{"type":23,"value":310},"Queer in AI Grad Admissions Fee Aid, 2022",{"type":13,"tag":252,"props":312,"children":313},{},[314],{"type":23,"value":315},"Honorable Mention, MCM/ICM Mathematical Contest 2020&2021",{"type":13,"tag":18,"props":317,"children":319},{"id":318},"contacts",[320],{"type":23,"value":321},"üìß Contacts",{"type":13,"tag":323,"props":324,"children":327},"contact-item",{"icon":325,"url":326},"email","mailto:ry273@cornell.edu",[328],{"type":13,"tag":26,"props":329,"children":330},{},[331],{"type":23,"value":332},"Email",{"type":13,"tag":323,"props":334,"children":337},{"icon":335,"url":336},"github","https://github.com/YoruCathy",[338],{"type":13,"tag":26,"props":339,"children":340},{},[341],{"type":23,"value":342},"GitHub",{"type":13,"tag":323,"props":344,"children":347},{"icon":345,"url":346},"twitter","https://twitter.com/Nekovowo",[348],{"type":13,"tag":26,"props":349,"children":350},{},[351],{"type":23,"value":352},"Twitter",{"type":13,"tag":323,"props":354,"children":357},{"icon":355,"url":356},"wechat","https://drive.google.com/file/d/1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ/view?usp=sharing",[358],{"type":13,"tag":26,"props":359,"children":360},{},[361],{"type":23,"value":362},"Wechat",{"title":5,"searchDepth":364,"depth":364,"links":365},2,[366,367,368,369,370],{"id":20,"depth":364,"text":24},{"id":81,"depth":364,"text":84},{"id":134,"depth":364,"text":137},{"id":235,"depth":364,"text":238},{"id":318,"depth":364,"text":321},"markdown","content:index.md","content","index.md","md",1738596079802]