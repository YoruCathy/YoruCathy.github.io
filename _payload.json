[{"data":1,"prerenderedAt":391},["Reactive",2],{"content-query-1DxZ1vYQk5":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"hideTitle":8,"disableFancyImage":8,"body":9,"_type":386,"_id":387,"_source":388,"_file":389,"_extension":390},"/","",false,"Home",true,{"type":10,"children":11,"toc":378},"root",[12,17,25,51,65,79,85,110,132,138,148,155,163,171,179,187,194,213,222,230,239,248,254,262,285,293,331,337,348,358,368],{"type":13,"tag":14,"props":15,"children":16},"element","IndexHeader",{},[],{"type":13,"tag":18,"props":19,"children":21},"h2",{"id":20},"about-me",[22],{"type":23,"value":24},"text","About Me",{"type":13,"tag":26,"props":27,"children":28},"p",{},[29,31,40,42,49],{"type":23,"value":30},"My name is Ruolin Ye. I am a fourth-year Ph.D. student at Cornell University supervised by ",{"type":13,"tag":32,"props":33,"children":37},"a",{"href":34,"rel":35},"https://sites.google.com/site/tapomayukh",[36],"nofollow",[38],{"type":23,"value":39},"Prof. Tapomayukh Bhattacharjee",{"type":23,"value":41},". I worked with ",{"type":13,"tag":32,"props":43,"children":46},{"href":44,"rel":45},"https://www.mvig.org/",[36],[47],{"type":23,"value":48},"Prof. Cewu Lu",{"type":23,"value":50},", in MVIG Lab during my undergrad at Shanghai Jiao Tong University.",{"type":13,"tag":26,"props":52,"children":53},{},[54,56,63],{"type":23,"value":55},"My broad research interest is robotic caregiving, and I am especially interested in robot-assisted transferring. I study how to coordinate multiple instrumented assistive devices to complete this task. I am also interested in simulation. I am leading the ",{"type":13,"tag":32,"props":57,"children":60},{"href":58,"rel":59},"https://emprise.cs.cornell.edu/rcareworld/",[36],[61],{"type":23,"value":62},"RCareWorld",{"type":23,"value":64}," simulation project.",{"type":13,"tag":26,"props":66,"children":67},{},[68,70,77],{"type":23,"value":69},"I volunteer at ",{"type":13,"tag":32,"props":71,"children":74},{"href":72,"rel":73},"https://www.wonderfulwheelchairs.info/home",[36],[75],{"type":23,"value":76},"Wonderful Wheelchairs",{"type":23,"value":78},", a local non-profit organization that repairs and sells assistive devices to people with a low cost.\nI manage the website and IT-related stuff while also leading outreach efforts.",{"type":13,"tag":18,"props":80,"children":82},{"id":81},"experiences",[83],{"type":23,"value":84},"ü•∑ Experiences",{"type":13,"tag":86,"props":87,"children":89},"ExperienceRow",{"icon":88},"cornell.png",[90],{"type":13,"tag":26,"props":91,"children":92},{},[93,99,103,105,108],{"type":13,"tag":94,"props":95,"children":96},"strong",{},[97],{"type":23,"value":98},"Cornell University, Ithaca, NY",{"type":13,"tag":100,"props":101,"children":102},"br",{},[],{"type":23,"value":104},"\nPh.D. Student in Computer Science",{"type":13,"tag":100,"props":106,"children":107},{},[],{"type":23,"value":109},"\nAug 2022 - Present",{"type":13,"tag":86,"props":111,"children":113},{"icon":112},"sjtu.png",[114],{"type":13,"tag":26,"props":115,"children":116},{},[117,122,125,127,130],{"type":13,"tag":94,"props":118,"children":119},{},[120],{"type":23,"value":121},"Shanghai Jiao Tong University, Shanghai, China",{"type":13,"tag":100,"props":123,"children":124},{},[],{"type":23,"value":126},"\nBachelor of Engineering in Information Engineering",{"type":13,"tag":100,"props":128,"children":129},{},[],{"type":23,"value":131},"\nSep 2018 - Aug 2022",{"type":13,"tag":18,"props":133,"children":135},{"id":134},"publications",[136],{"type":23,"value":137},"üìÑ Publications",{"type":13,"tag":139,"props":140,"children":147},"PublicationRow",{":artifactLinks":141,":authors":142,":venue":143,"thumbnail":144,"title":145,"type":146},"{\"Paper\":\"https://ieeexplore.ieee.org/abstract/document/10973913/authors#authors\"}","[\"Shuaixing Chen\",\"Ruolin Ye\",\"Saurabh Dingwani\",\"Pooyan Fazli\",\"Hasti Seifi\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"HRI\",\"year\":2025,\"name\":\"ACM/IEEE International Conference on Human-Robot Interaction\"}","rcaregen.png","RCareGen: An Interface for Scene and Task Generation in RCareWorld","conference",[],{"type":13,"tag":139,"props":149,"children":154},{":artifactLinks":150,":authors":151,":venue":143,"thumbnail":152,"title":153,"type":146},"{\"Paper\":\"https://arxiv.org/abs/2501.11149\",\"Website\":\"https://emprise.cs.cornell.edu/cart-mpc/\"}","[\"Ruolin Ye*\",\"Shuaixing Chen*\",\"Yunting Yan*\",\"Joyce Yang\",\"Christina Ge\",\"Jose Barreiros\",\"Kate Tsui\",\"Tom Silver\",\"Tapomayukh Bhattacharjee\"]","cartmpc.png","CART-MPC: Coordinating Assistive Devices for Robot-Assisted Transferring with Multi-Agent Model Predictive Control",[],{"type":13,"tag":139,"props":156,"children":162},{":artifactLinks":157,":authors":158,":venue":159,"thumbnail":160,"title":161,"type":146},"{\"Paper\":\"https://arxiv.org/abs/2410.10017\",\"Website\":\"https://emprise.cs.cornell.edu/repeat/\"}","[\"Nayoung Ha*\",\"Ruolin Ye*\",\"Ziang Liu\",\"Shubhangi Sinha\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2024,\"name\":\"International Conference on Intelligent Robots and Systems\"}","repeat.png","REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding",[],{"type":13,"tag":139,"props":164,"children":170},{":artifactLinks":165,":authors":166,":venue":167,"thumbnail":168,"title":169,"type":146},"{\"Paper\":\"https://ieeexplore.ieee.org/abstract/document/10610050\",\"Website\":\"https://emprise.cs.cornell.edu/morpheus/\"}","[\"Ruolin Ye\",\"Yifei Hu\",\"Yuhan (Anjelica) Bian\",\"Luke Kulm\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"ICRA\",\"year\":2024,\"name\":\"IEEE International Conference on Robotics and Automation\"}","peeling.png","MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop",[],{"type":13,"tag":139,"props":172,"children":178},{":artifactLinks":173,":authors":174,":venue":175,"thumbnail":176,"title":177,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu\",\"Wenxin Du\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV (Oral)\",\"year\":2023,\"name\":\"International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",[],{"type":13,"tag":139,"props":180,"children":186},{":artifactLinks":181,":authors":182,":venue":183,"thumbnail":184,"title":185,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"Website\":\"https://sites.google.com/view/vtaco/\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vtaco\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu\"]","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"The IEEE/CVF Conference on Computer Vision and Pattern Recognition\"}","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction",[],{"type":13,"tag":139,"props":188,"children":193},{":artifactLinks":189,":authors":190,":venue":183,"thumbnail":191,"title":192,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"Website\":\"https://garment-tracking.robotflow.ai/\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vr-folding\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\"}","[\"Han Xue*\",\"Wenqiang Xu*\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","garmentTracking.png","GarmentTracking: Category-Level Garment Pose Tracking",[],{"type":13,"tag":139,"props":195,"children":201},{":artifactLinks":196,":authors":197,":venue":198,"thumbnail":199,"title":200,"type":146},"{\"Paper\":\"https://drive.google.com/file/d/1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28/view\",\"Code\":\"https://github.com/empriselab/RCareWorld\",\"Website\":\"https://emprise.cs.cornell.edu/rcareworld/\",\"Presentation\":\"https://www.youtube.com/watch?v=mNy1cloWrP0\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Haoyuan Fu\",\"Rajat Kumar Jenamani\",\"Vy Nguyen\",\"Cewu Lu\",\"Katherine Dimitropoulou\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2022,\"name\":\"IEEE/RSJ International Conference on Intelligent Robots and Systems\"}","rcareworld.png","RCareWorld: A Human-centric Simulation World for Caregiving Robots",[202],{"type":13,"tag":26,"props":203,"children":204},{},[205],{"type":13,"tag":206,"props":207,"children":210},"span",{"className":208},[209],"text-red-700",[211],{"type":23,"value":212},"Best RoboCup paper (Winner). Best paper/best student paper (Finalist).",{"type":13,"tag":139,"props":214,"children":221},{":artifactLinks":215,":authors":216,":venue":217,"thumbnail":218,"title":219,"type":220},"{\"Website\":\"https://sites.google.com/view/rfuniverse\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Zhenjun Yu\",\"Jieyi Zhang\",\"Yongxi Huang\",\"Cewu Lu\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics Science and Systems\"}","rfuniverse.png","RFUniverse: A Multiphysics Simulation Platform for Embodied AI","insubmission",[],{"type":13,"tag":139,"props":223,"children":229},{":artifactLinks":224,":authors":225,":venue":226,"thumbnail":227,"title":228,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf\",\"Website\":\"https://sites.google.com/view/handover-h2o/home\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Zhendong Xue\",\"Tutian Tang\",\"Yanfeng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV\",\"year\":2021,\"name\":\"International Conference on Computer Vision\"}","h2o.png","H2O: A Benchmark for Visual Human-human Object Handover Analysis",[],{"type":13,"tag":139,"props":231,"children":238},{":artifactLinks":232,":authors":233,":venue":234,"thumbnail":235,"title":236,"type":237},"{\"Paper\":\"https://arxiv.org/pdf/2012.01050.pdf\",\"Code\":\"https://github.com/YoruCathy/USDSeg-FCOS\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Lixin Yang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2020,\"name\":\"Preprint\"}","usd-seg.png","Learning Universal Shape Dictionary for Realtime Instance Segmentation","preprint",[],{"type":13,"tag":139,"props":240,"children":247},{":artifactLinks":241,":authors":242,":venue":243,"thumbnail":244,"title":245,"type":237,":hideBottomBorder":246},"{\"Paper\":\"https://arxiv.org/pdf/2106.03382.pdf\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2021,\"name\":\"Preprint\"}","contour.png","ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass","true",[],{"type":13,"tag":18,"props":249,"children":251},{"id":250},"Ô∏è-services-and-awards",[252],{"type":23,"value":253},"‚ù§Ô∏è Services and Awards",{"type":13,"tag":26,"props":255,"children":256},{},[257],{"type":13,"tag":94,"props":258,"children":259},{},[260],{"type":23,"value":261},"Academic services",{"type":13,"tag":263,"props":264,"children":265},"ul",{},[266],{"type":13,"tag":267,"props":268,"children":269},"li",{},[270,272],{"type":23,"value":271},"Reviewer\n",{"type":13,"tag":263,"props":273,"children":274},{},[275,280],{"type":13,"tag":267,"props":276,"children":277},{},[278],{"type":23,"value":279},"Conferences: ICCV 2023, CVPR 2022&2023, ECCV 2022, IROS 2022-2024, ICRA 2023-2024, HRI 2025",{"type":13,"tag":267,"props":281,"children":282},{},[283],{"type":23,"value":284},"Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics, T-RO",{"type":13,"tag":26,"props":286,"children":287},{},[288],{"type":13,"tag":94,"props":289,"children":290},{},[291],{"type":23,"value":292},"Awards",{"type":13,"tag":263,"props":294,"children":295},{},[296,301,306,311,316,321,326],{"type":13,"tag":267,"props":297,"children":298},{},[299],{"type":23,"value":300},"Outstading teaching assistant, Cornell 2024",{"type":13,"tag":267,"props":302,"children":303},{},[304],{"type":23,"value":305},"IROS-SDC Travel Award, IROS 2022",{"type":13,"tag":267,"props":307,"children":308},{},[309],{"type":23,"value":310},"RoboCup Best Paper Award, IROS 2022",{"type":13,"tag":267,"props":312,"children":313},{},[314],{"type":23,"value":315},"Best Paper/Student Paper Finalist, IROS 2022",{"type":13,"tag":267,"props":317,"children":318},{},[319],{"type":23,"value":320},"Bosch AIoT Scholarship, 2022",{"type":13,"tag":267,"props":322,"children":323},{},[324],{"type":23,"value":325},"Queer in AI Grad Admissions Fee Aid, 2022",{"type":13,"tag":267,"props":327,"children":328},{},[329],{"type":23,"value":330},"Honorable Mention, MCM/ICM Mathematical Contest 2020&2021",{"type":13,"tag":18,"props":332,"children":334},{"id":333},"contacts",[335],{"type":23,"value":336},"üìß Contacts",{"type":13,"tag":338,"props":339,"children":342},"contact-item",{"icon":340,"url":341},"email","mailto:ry273@cornell.edu",[343],{"type":13,"tag":26,"props":344,"children":345},{},[346],{"type":23,"value":347},"Email",{"type":13,"tag":338,"props":349,"children":352},{"icon":350,"url":351},"github","https://github.com/YoruCathy",[353],{"type":13,"tag":26,"props":354,"children":355},{},[356],{"type":23,"value":357},"GitHub",{"type":13,"tag":338,"props":359,"children":362},{"icon":360,"url":361},"twitter","https://twitter.com/Nekovowo",[363],{"type":13,"tag":26,"props":364,"children":365},{},[366],{"type":23,"value":367},"Twitter",{"type":13,"tag":338,"props":369,"children":372},{"icon":370,"url":371},"wechat","https://drive.google.com/file/d/1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ/view?usp=sharing",[373],{"type":13,"tag":26,"props":374,"children":375},{},[376],{"type":23,"value":377},"Wechat",{"title":5,"searchDepth":379,"depth":379,"links":380},2,[381,382,383,384,385],{"id":20,"depth":379,"text":24},{"id":81,"depth":379,"text":84},{"id":134,"depth":379,"text":137},{"id":250,"depth":379,"text":253},{"id":333,"depth":379,"text":336},"markdown","content:index.md","content","index.md","md",1757020241178]