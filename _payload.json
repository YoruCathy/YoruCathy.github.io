[{"data":1,"prerenderedAt":390},["Reactive",2],{"content-query-1DxZ1vYQk5":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"hideTitle":8,"disableFancyImage":8,"body":9,"_type":385,"_id":386,"_source":387,"_file":388,"_extension":389},"/","",false,"Home",true,{"type":10,"children":11,"toc":377},"root",[12,17,25,51,65,79,85,110,132,138,148,154,162,170,178,186,193,212,221,229,238,247,253,261,284,292,330,336,347,357,367],{"type":13,"tag":14,"props":15,"children":16},"element","IndexHeader",{},[],{"type":13,"tag":18,"props":19,"children":21},"h2",{"id":20},"about-me",[22],{"type":23,"value":24},"text","About Me",{"type":13,"tag":26,"props":27,"children":28},"p",{},[29,31,40,42,49],{"type":23,"value":30},"My name is Ruolin Ye. I am a fourth-year Ph.D. student at Cornell University supervised by ",{"type":13,"tag":32,"props":33,"children":37},"a",{"href":34,"rel":35},"https://sites.google.com/site/tapomayukh",[36],"nofollow",[38],{"type":23,"value":39},"Prof. Tapomayukh Bhattacharjee",{"type":23,"value":41},". I worked with ",{"type":13,"tag":32,"props":43,"children":46},{"href":44,"rel":45},"https://www.mvig.org/",[36],[47],{"type":23,"value":48},"Prof. Cewu Lu",{"type":23,"value":50},", in MVIG Lab during my undergrad at Shanghai Jiao Tong University.",{"type":13,"tag":26,"props":52,"children":53},{},[54,56,63],{"type":23,"value":55},"My broad research interest is robotic caregiving, and I am especially interested in robot-assisted transferring. I study how to coordinate multiple instrumented assistive devices to complete this task. I am also interested in simulation. I am leading the ",{"type":13,"tag":32,"props":57,"children":60},{"href":58,"rel":59},"https://emprise.cs.cornell.edu/rcareworld/",[36],[61],{"type":23,"value":62},"RCareWorld",{"type":23,"value":64}," simulation project.",{"type":13,"tag":26,"props":66,"children":67},{},[68,70,77],{"type":23,"value":69},"I volunteer at ",{"type":13,"tag":32,"props":71,"children":74},{"href":72,"rel":73},"https://www.wonderfulwheelchairs.info/home",[36],[75],{"type":23,"value":76},"Wonderful Wheelchairs",{"type":23,"value":78},", a local non-profit organization that repairs and sells assistive devices to people with a low cost.\nI manage the website and IT-related stuff while also leading outreach efforts.",{"type":13,"tag":18,"props":80,"children":82},{"id":81},"experiences",[83],{"type":23,"value":84},"ü•∑ Experiences",{"type":13,"tag":86,"props":87,"children":89},"ExperienceRow",{"icon":88},"cornell.png",[90],{"type":13,"tag":26,"props":91,"children":92},{},[93,99,103,105,108],{"type":13,"tag":94,"props":95,"children":96},"strong",{},[97],{"type":23,"value":98},"Cornell University, Ithaca, NY",{"type":13,"tag":100,"props":101,"children":102},"br",{},[],{"type":23,"value":104},"\nPh.D. Student in Computer Science",{"type":13,"tag":100,"props":106,"children":107},{},[],{"type":23,"value":109},"\nAug 2022 - Present",{"type":13,"tag":86,"props":111,"children":113},{"icon":112},"sjtu.png",[114],{"type":13,"tag":26,"props":115,"children":116},{},[117,122,125,127,130],{"type":13,"tag":94,"props":118,"children":119},{},[120],{"type":23,"value":121},"Shanghai Jiao Tong University, Shanghai, China",{"type":13,"tag":100,"props":123,"children":124},{},[],{"type":23,"value":126},"\nBachelor of Engineering in Information Engineering",{"type":13,"tag":100,"props":128,"children":129},{},[],{"type":23,"value":131},"\nSep 2018 - Aug 2022",{"type":13,"tag":18,"props":133,"children":135},{"id":134},"publications",[136],{"type":23,"value":137},"üìÑ Publications",{"type":13,"tag":139,"props":140,"children":147},"PublicationRow",{":artifactLinks":141,":authors":142,":venue":143,"thumbnail":144,"title":145,"type":146},"{\"Paper\":\"https://ieeexplore.ieee.org/abstract/document/10973913/authors#authors\"}","[\"Shuaixing Chen\",\"Ruolin Ye\",\"Saurabh Dingwani\",\"Pooyan Fazli\",\"Hasti Seifi\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"HRI\",\"year\":2025,\"name\":\"ACM/IEEE International Conference on Human-Robot Interaction\"}","cartmpc.png","RCareGen: An Interface for Scene and Task Generation in RCareWorld","conference",[],{"type":13,"tag":139,"props":149,"children":153},{":artifactLinks":150,":authors":151,":venue":143,"thumbnail":144,"title":152,"type":146},"{\"Paper\":\"https://arxiv.org/abs/2501.11149\",\"Website\":\"https://emprise.cs.cornell.edu/cart-mpc/\"}","[\"Ruolin Ye*\",\"Shuaixing Chen*\",\"Yunting Yan*\",\"Joyce Yang\",\"Christina Ge\",\"Jose Barreiros\",\"Kate Tsui\",\"Tom Silver\",\"Tapomayukh Bhattacharjee\"]","CART-MPC: Coordinating Assistive Devices for Robot-Assisted Transferring with Multi-Agent Model Predictive Control",[],{"type":13,"tag":139,"props":155,"children":161},{":artifactLinks":156,":authors":157,":venue":158,"thumbnail":159,"title":160,"type":146},"{\"Paper\":\"https://arxiv.org/abs/2410.10017\",\"Website\":\"https://emprise.cs.cornell.edu/repeat/\"}","[\"Nayoung Ha*\",\"Ruolin Ye*\",\"Ziang Liu\",\"Shubhangi Sinha\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2024,\"name\":\"International Conference on Intelligent Robots and Systems\"}","repeat.png","REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding",[],{"type":13,"tag":139,"props":163,"children":169},{":artifactLinks":164,":authors":165,":venue":166,"thumbnail":167,"title":168,"type":146},"{\"Paper\":\"https://ieeexplore.ieee.org/abstract/document/10610050\",\"Website\":\"https://emprise.cs.cornell.edu/morpheus/\"}","[\"Ruolin Ye\",\"Yifei Hu\",\"Yuhan (Anjelica) Bian\",\"Luke Kulm\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"ICRA\",\"year\":2024,\"name\":\"IEEE International Conference on Robotics and Automation\"}","peeling.png","MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop",[],{"type":13,"tag":139,"props":171,"children":177},{":artifactLinks":172,":authors":173,":venue":174,"thumbnail":175,"title":176,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu\",\"Wenxin Du\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV (Oral)\",\"year\":2023,\"name\":\"International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution",[],{"type":13,"tag":139,"props":179,"children":185},{":artifactLinks":180,":authors":181,":venue":182,"thumbnail":183,"title":184,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"Website\":\"https://sites.google.com/view/vtaco/\",\"Code\":\"https://github.com/jeffsonyu/VTacO\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vtaco\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu\"]","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"The IEEE/CVF Conference on Computer Vision and Pattern Recognition\"}","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction",[],{"type":13,"tag":139,"props":187,"children":192},{":artifactLinks":188,":authors":189,":venue":182,"thumbnail":190,"title":191,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"Website\":\"https://garment-tracking.robotflow.ai/\",\"Dataset\":\"https://huggingface.co/datasets/robotflow/vr-folding\",\"Code\":\"https://github.com/xiaoxiaoxh/GarmentTracking\"}","[\"Han Xue*\",\"Wenqiang Xu*\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","garmentTracking.png","GarmentTracking: Category-Level Garment Pose Tracking",[],{"type":13,"tag":139,"props":194,"children":200},{":artifactLinks":195,":authors":196,":venue":197,"thumbnail":198,"title":199,"type":146},"{\"Paper\":\"https://drive.google.com/file/d/1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28/view\",\"Code\":\"https://github.com/empriselab/RCareWorld\",\"Website\":\"https://emprise.cs.cornell.edu/rcareworld/\",\"Presentation\":\"https://www.youtube.com/watch?v=mNy1cloWrP0\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Haoyuan Fu\",\"Rajat Kumar Jenamani\",\"Vy Nguyen\",\"Cewu Lu\",\"Katherine Dimitropoulou\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2022,\"name\":\"IEEE/RSJ International Conference on Intelligent Robots and Systems\"}","rcareworld.png","RCareWorld: A Human-centric Simulation World for Caregiving Robots",[201],{"type":13,"tag":26,"props":202,"children":203},{},[204],{"type":13,"tag":205,"props":206,"children":209},"span",{"className":207},[208],"text-red-700",[210],{"type":23,"value":211},"Best RoboCup paper (Winner). Best paper/best student paper (Finalist).",{"type":13,"tag":139,"props":213,"children":220},{":artifactLinks":214,":authors":215,":venue":216,"thumbnail":217,"title":218,"type":219},"{\"Website\":\"https://sites.google.com/view/rfuniverse\",\"Code\":\"https://github.com/mvig-robotflow/pyrfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Zhenjun Yu\",\"Jieyi Zhang\",\"Yongxi Huang\",\"Cewu Lu\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics Science and Systems\"}","rfuniverse.png","RFUniverse: A Multiphysics Simulation Platform for Embodied AI","insubmission",[],{"type":13,"tag":139,"props":222,"children":228},{":artifactLinks":223,":authors":224,":venue":225,"thumbnail":226,"title":227,"type":146},"{\"Paper\":\"https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf\",\"Website\":\"https://sites.google.com/view/handover-h2o/home\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Zhendong Xue\",\"Tutian Tang\",\"Yanfeng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV\",\"year\":2021,\"name\":\"International Conference on Computer Vision\"}","h2o.png","H2O: A Benchmark for Visual Human-human Object Handover Analysis",[],{"type":13,"tag":139,"props":230,"children":237},{":artifactLinks":231,":authors":232,":venue":233,"thumbnail":234,"title":235,"type":236},"{\"Paper\":\"https://arxiv.org/pdf/2012.01050.pdf\",\"Code\":\"https://github.com/YoruCathy/USDSeg-FCOS\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Lixin Yang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2020,\"name\":\"Preprint\"}","usd-seg.png","Learning Universal Shape Dictionary for Realtime Instance Segmentation","preprint",[],{"type":13,"tag":139,"props":239,"children":246},{":artifactLinks":240,":authors":241,":venue":242,"thumbnail":243,"title":244,"type":236,":hideBottomBorder":245},"{\"Paper\":\"https://arxiv.org/pdf/2106.03382.pdf\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2021,\"name\":\"Preprint\"}","contour.png","ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass","true",[],{"type":13,"tag":18,"props":248,"children":250},{"id":249},"Ô∏è-services-and-awards",[251],{"type":23,"value":252},"‚ù§Ô∏è Services and Awards",{"type":13,"tag":26,"props":254,"children":255},{},[256],{"type":13,"tag":94,"props":257,"children":258},{},[259],{"type":23,"value":260},"Academic services",{"type":13,"tag":262,"props":263,"children":264},"ul",{},[265],{"type":13,"tag":266,"props":267,"children":268},"li",{},[269,271],{"type":23,"value":270},"Reviewer\n",{"type":13,"tag":262,"props":272,"children":273},{},[274,279],{"type":13,"tag":266,"props":275,"children":276},{},[277],{"type":23,"value":278},"Conferences: ICCV 2023, CVPR 2022&2023, ECCV 2022, IROS 2022-2024, ICRA 2023-2024, HRI 2025",{"type":13,"tag":266,"props":280,"children":281},{},[282],{"type":23,"value":283},"Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics, T-RO",{"type":13,"tag":26,"props":285,"children":286},{},[287],{"type":13,"tag":94,"props":288,"children":289},{},[290],{"type":23,"value":291},"Awards",{"type":13,"tag":262,"props":293,"children":294},{},[295,300,305,310,315,320,325],{"type":13,"tag":266,"props":296,"children":297},{},[298],{"type":23,"value":299},"Outstading teaching assistant, Cornell 2024",{"type":13,"tag":266,"props":301,"children":302},{},[303],{"type":23,"value":304},"IROS-SDC Travel Award, IROS 2022",{"type":13,"tag":266,"props":306,"children":307},{},[308],{"type":23,"value":309},"RoboCup Best Paper Award, IROS 2022",{"type":13,"tag":266,"props":311,"children":312},{},[313],{"type":23,"value":314},"Best Paper/Student Paper Finalist, IROS 2022",{"type":13,"tag":266,"props":316,"children":317},{},[318],{"type":23,"value":319},"Bosch AIoT Scholarship, 2022",{"type":13,"tag":266,"props":321,"children":322},{},[323],{"type":23,"value":324},"Queer in AI Grad Admissions Fee Aid, 2022",{"type":13,"tag":266,"props":326,"children":327},{},[328],{"type":23,"value":329},"Honorable Mention, MCM/ICM Mathematical Contest 2020&2021",{"type":13,"tag":18,"props":331,"children":333},{"id":332},"contacts",[334],{"type":23,"value":335},"üìß Contacts",{"type":13,"tag":337,"props":338,"children":341},"contact-item",{"icon":339,"url":340},"email","mailto:ry273@cornell.edu",[342],{"type":13,"tag":26,"props":343,"children":344},{},[345],{"type":23,"value":346},"Email",{"type":13,"tag":337,"props":348,"children":351},{"icon":349,"url":350},"github","https://github.com/YoruCathy",[352],{"type":13,"tag":26,"props":353,"children":354},{},[355],{"type":23,"value":356},"GitHub",{"type":13,"tag":337,"props":358,"children":361},{"icon":359,"url":360},"twitter","https://twitter.com/Nekovowo",[362],{"type":13,"tag":26,"props":363,"children":364},{},[365],{"type":23,"value":366},"Twitter",{"type":13,"tag":337,"props":368,"children":371},{"icon":369,"url":370},"wechat","https://drive.google.com/file/d/1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ/view?usp=sharing",[372],{"type":13,"tag":26,"props":373,"children":374},{},[375],{"type":23,"value":376},"Wechat",{"title":5,"searchDepth":378,"depth":378,"links":379},2,[380,381,382,383,384],{"id":20,"depth":378,"text":24},{"id":81,"depth":378,"text":84},{"id":134,"depth":378,"text":137},{"id":249,"depth":378,"text":252},{"id":332,"depth":378,"text":335},"markdown","content:index.md","content","index.md","md",1757019687250]