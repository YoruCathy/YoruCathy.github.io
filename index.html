<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Home - Ruolin Ye</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê±</text></svg>">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css"><link rel="modulepreload" href="/_payload.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.d2d75a21.js"><link rel="preload" as="style" href="/_nuxt/entry.d049ffb0.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.b74b1f73.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.84c00a02.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.a86455b3.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.a9b16923.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_commonjsHelpers.fed2a411.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.3092278b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/layout.2f217143.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.fb96d3b9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.e22e54d6.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.eb2e574b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.276c8668.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.790c7fb2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.0a6d8efd.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.b3ba153d.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.7e90a6db.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.a1a6add7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.764d77ad.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.87d899df.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.6b6e4844.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ShortNews.a166ade8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.a98e994c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentSlot.127fe4c8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.8a73ad73.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.a587cb54.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.20448ab5.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.11557dd1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.06b7bfdc.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.d40cf4c4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.c55f625c.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentNavigation.5ad0e99a.js"><link rel="prefetch" as="style" href="/_nuxt/ContentNavigation.8ff1cb40.css"><link rel="prefetch" as="style" href="/_nuxt/IndexHeader.6f25759d.css"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.98512176.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Markdown.400da14b.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ProseCode.11a51055.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.49440b15.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.8f135109.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/web-socket.7722c56f.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.35832ccd.js"><link rel="stylesheet" href="/_nuxt/entry.d049ffb0.css"><style>body{background-color:rgb(250 250 249/var(--tw-bg-opacity))}.dark body,body{--tw-bg-opacity:1}.dark body{background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear,color .1s linear}a:hover{color:#fc639b!important;opacity:.8}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><style>body{background-color:#fff8fb}footer{background-color:#efdfe6!important}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><!--[--><div class="document-driven-page"><!--[--><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="https://drive.google.com/file/d/1Rm20DVSZvu6pd_0PwKdaiSB6snXbo1nM/view?usp=sharing"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="https://drive.google.com/file/d/1Rm20DVSZvu6pd_0PwKdaiSB6snXbo1nM/view?usp=sharing"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">CV</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-8 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-[#e4c7d3] dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Ruolin Ye</p><p class="w-full text-xl prose dark:prose-invert m-0 text-left"> (She/Her) <br> First-year Ph.D. Student in Computer Science<a href="https://emprise.cs.cornell.edu">@EmPRISELab</a>, Cornell University<br> Research: Human-robot interaction, Simulation </p><p class="mt-4 w-full m-0"><span class="m-0"><a href="mailto:ry273@cornell.edu"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YoruCathy"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://twitter.com/nekovowo"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a><a href="https://scholar.google.com/citations?user=fCy8NOUAAAAJ&amp;hl=en"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/google-scholar.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/cathy.png" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-100" src="/assets/img/cathy-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-[#efdfe6] dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/cathy.png" alt=""></div></div></div></div></div><h2 id="about-me"><a href="#about-me"><!--[-->üê± About Me<!--]--></a></h2><p><!--[-->My name is Ruolin Ye. I am a second-year Ph.D. student at Cornell University supervised by <a href="https://sites.google.com/site/tapomayukh" rel="nofollow"><!--[-->Prof. Tapomayukh Bhattacharjee<!--]--></a>. Before that, I worked as an intern at ZenusTech supervised by <a href="https://scholar.google.com/citations?hl=en&amp;user=SU6DkyYAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="nofollow"><!--[-->Dr. Xinxin Zhang<!--]--></a>. I worked with <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Prof. Cewu Lu<!--]--></a>, in MVIG Lab during my undergrad at Shanghai Jiao Tong University.
My research interest includes human-robot collaboration and simulation.
If you find any research interest we may share, or some intersection on projects I am working on, please feel free to drop me an Email. I am always open to collaboration.
In my spare time, I enjoy <a href="https://www.instagram.com/p/Cmf3pXtOFh1/?utm_source=ig_web_copy_link" rel="nofollow"><!--[-->sketching<!--]--></a>, <a href="https://www.instagram.com/p/CRWg7z9grr0/" rel="nofollow"><!--[-->watching musicals<!--]--></a>, and making <a href="https://www.instagram.com/p/CPifY_Vg7VY/" rel="nofollow"><!--[-->cocktails<!--]--></a>.<!--]--></p><h2 id="news"><a href="#news"><!--[-->üì∞ News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><!--[--><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">üì¢ Latest: I&#39;m a Ph.D. candidate now!</h2><!--]--><p><!--[--><img src="/assets/img/me-news-google.png" alt><!--]--></p><ul><!--[--><li><!--[--><strong><!--[-->05/2023<!--]--></strong> üéâ RFUniverse accepted by RSS 2023 Demo Track!<!--]--></li><li><!--[--><strong><!--[-->02/2023<!--]--></strong> üéâ 2 papers accepted by CVPR 2023!<!--]--></li><li><!--[--><strong><!--[-->10/2022<!--]--></strong> üéâ RCareWorld won the RoboCup Best Paper Award!<!--]--></li><li><!--[--><strong><!--[-->09/2022<!--]--></strong> üéâ Received IROS-SDC Travel Award!<!--]--></li><li><!--[--><strong><!--[-->08/2022<!--]--></strong> ‚ú® Starting my research journey as a PhD student!<!--]--></li><li><!--[--><strong><!--[-->07/2022<!--]--></strong> üéâ RCareWorld accepted by IROS 2022!<!--]--></li><li><!--[--><strong><!--[-->07/2021<!--]--></strong> üéâ H2O accepted by ICCV 2022!<!--]--></li><!--]--></ul></div><!--]--></div><h2 id="experiences"><a href="#experiences"><!--[-->ü•∑ Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-cornell.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/cornell.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Cornell University, Ithaca, NY<!--]--></strong><br>
Ph.D. Student in Computer Science<br>
Aug 2022 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-sjtu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/sjtu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Shanghai Jiao Tong University, Shanghai, China<!--]--></strong><br>
Bachelor of Engineering in Information Engineering<br>
Sep 2018 - Aug 2022<!--]--></p><!--]--><!--]--></div></div><h2 id="publications"><a href="#publications"><!--[-->üìÑ Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">In submission&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm">Paper (Coming soon)</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/peeling.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yifei Hu</span><span>,¬†</span></span><span><span class="">Yuhan (Anjelica) Bian</span><span>,¬†</span></span><span><span class="">Luke Kulm</span><span>,¬†</span></span><span><span class="">Tapomayukh Bhattacharjee</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">In submission</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICCV (Oral)&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm">Paper</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/clothpose.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yan-feng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">International Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/vtaco/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/jeffsonyu/VTacO">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://huggingface.co/datasets/robotflow/vtaco">Dataset</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Visual-Tactile Sensing for In-Hand Object Reconstruction</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/vtaco.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Zhenjun Yu*</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Siqiong Yao</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">The IEEE/CVF Conference on Computer Vision and Pattern Recognition</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://garment-tracking.robotflow.ai/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://huggingface.co/datasets/robotflow/vr-folding">Dataset</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/GarmentTracking">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">GarmentTracking: Category-Level Garment Pose Tracking</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/garmentTracking.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Han Xue*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Jieyi Zhang</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">The IEEE/CVF Conference on Computer Vision and Pattern Recognition</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IROS&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28/view">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/empriselab/RCareWorld">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://emprise.cs.cornell.edu/rcareworld/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.youtube.com/watch?v=mNy1cloWrP0">Presentation</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">RCareWorld: A Human-centric Simulation World for Caregiving Robots</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rcareworld.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Haoyuan Fu</span><span>,¬†</span></span><span><span class="">Rajat Kumar Jenamani</span><span>,¬†</span></span><span><span class="">Vy Nguyen</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>,¬†</span></span><span><span class="">Katherine Dimitropoulou</span><span>,¬†</span></span><span><span class="">Tapomayukh Bhattacharjee</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE/RSJ International Conference on Intelligent Robots and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-700">Best RoboCup paper (Winner). Best paper/best student paper (Finalist).</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="insubmission"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">RSS&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/rfuniverse">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/mvig-robotflow/pyrfuniverse">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">RFUniverse: A Multiphysics Simulation Platform for Embodied AI</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rfuniverse.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Haoyuan Fu*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="">Zhenjun Yu</span><span>,¬†</span></span><span><span class="">Jieyi Zhang</span><span>,¬†</span></span><span><span class="">Yongxi Huang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Robotics Science and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICCV&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/handover-h2o/home">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">H2O: A Benchmark for Visual Human-human Object Handover Analysis</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/h2o.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Zhendong Xue</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yanfeng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">International Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="preprint"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">arXiv&#39;20</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2012.01050.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/YoruCathy/USDSeg-FCOS">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Learning Universal Shape Dictionary for Realtime Instance Segmentation</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/usd-seg.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Tutian Tang*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Lixin Yang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Preprint</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8" type="preprint"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">arXiv&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2106.03382.pdf">Paper</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/contour.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Tutian Tang*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yan-feng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Preprint</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><h2 id="Ô∏è-services-and-awards"><a href="#Ô∏è-services-and-awards"><!--[-->‚ù§Ô∏è Services and Awards<!--]--></a></h2><p><!--[--><strong><!--[-->Academic services<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->Reviewer<ul><!--[--><li><!--[-->Conferences: ICCV 2023, CVPR 2022&amp;2023, ECCV 2022, IROS 2022, ICRA 2023<!--]--></li><li><!--[-->Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics<!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->Awards<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->IROS-SDC Travel Award, IROS 2022<!--]--></li><li><!--[-->RoboCup Best Paper Award, IROS 2022<!--]--></li><li><!--[-->Best Paper/Student Paper Finalist, IROS 2022<!--]--></li><li><!--[-->Bosch AIoT Scholarship, 2022<!--]--></li><li><!--[-->Queer in AI Grad Admissions Fee Aid, 2022<!--]--></li><li><!--[-->Honorable Mention, MCM/ICM Mathematical Contest 2020&amp;2021<!--]--></li><!--]--></ul><h2 id="contacts"><a href="#contacts"><!--[-->üìß Contacts<!--]--></a></h2><span><a href="mailto:ry273@cornell.edu" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/YoruCathy" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/Nekovowo" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span><span><a href="https://drive.google.com/file/d/1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ/view?usp=sharing" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/wechat.svg" alt=""><!--[-->Wechat<!--]--></a></span></div><!--]--></article><footer class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> Âè∂Ëã•Áê≥ | Ruolin <br> CS Ph.D. Student <a href="https://emprise.cs.cornell.edu">EmPRISE Lab, Cornell University</a> <br> Research Interests: Human robot interaction, Intelligent devices, Simulation </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:ry273@cornell.edu">E-Mail</a> <br><a href="https://github.com/YoruCathy">GitHub</a> <br><a href="https://twitter.com/Nekovowo">Twitter</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> ¬© <a href="/">Ruolin Ye</a> 2023. Last updated: 9/20/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template made by Yiqin Zhao</a>. </p></div></div></footer><!--]--><!--]--></div><!--]--><!--]--></div><script type="module">import p from "/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb,bc,bd,be,bf,bg,bh,bi,bj,bk,bl,bm,bn,bo,bp,bq,br,bs,bt,bu,bv,bw,bx,by,bz,bA,bB,bC,bD,bE,bF,bG,bH,bI){return {state:{"$scolor-mode":{preference:K,value:K,unknown:k,forced:l},"$sdd-pages":{"/":{_path:v,_dir:m,_draft:l,_partial:l,_locale:L,_empty:l,title:M,description:m,excerpt:{type:w,children:[{type:a,tag:N,props:{},children:[]},{type:a,tag:g,props:{id:x},children:[{type:b,value:y}]},{type:a,tag:d,props:{},children:[{type:b,value:O},{type:a,tag:h,props:{href:P,rel:[i]},children:[{type:b,value:Q}]},{type:b,value:R},{type:a,tag:h,props:{href:S,rel:[i]},children:[{type:b,value:T}]},{type:b,value:U},{type:a,tag:h,props:{href:V,rel:[i]},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:h,props:{href:Y,rel:[i]},children:[{type:b,value:Z}]},{type:b,value:_},{type:a,tag:h,props:{href:$,rel:[i]},children:[{type:b,value:aa}]},{type:b,value:ab},{type:a,tag:h,props:{href:ac,rel:[i]},children:[{type:b,value:ad}]},{type:b,value:ae}]},{type:a,tag:g,props:{id:z},children:[{type:b,value:A}]},{type:a,tag:af,props:{},children:[]},{type:a,tag:g,props:{id:B},children:[{type:b,value:C}]},{type:a,tag:s,props:{icon:ag},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:ah}]},{type:a,tag:n,props:{},children:[]},{type:b,value:ai},{type:a,tag:n,props:{},children:[]},{type:b,value:aj}]}]},{type:a,tag:s,props:{icon:ak},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:al}]},{type:a,tag:n,props:{},children:[]},{type:b,value:am},{type:a,tag:n,props:{},children:[]},{type:b,value:an}]}]},{type:a,tag:g,props:{id:D},children:[{type:b,value:E}]},{type:a,tag:e,props:{":artifactLinks":ao,":authors":ap,":venue":aq,thumbnail:ar,title:as,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":at,":authors":au,":venue":av,thumbnail:aw,title:ax,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":ay,":authors":az,":venue":t,thumbnail:aA,title:aB,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aC,":authors":aD,":venue":t,thumbnail:aE,title:aF,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aG,":authors":aH,":venue":aI,thumbnail:aJ,title:aK,type:j},children:[{type:a,tag:d,props:{},children:[{type:a,tag:aL,props:{className:[aM]},children:[{type:b,value:aN}]}]}]},{type:a,tag:e,props:{":artifactLinks":aO,":authors":aP,":venue":aQ,thumbnail:aR,title:aS,type:aT},children:[]},{type:a,tag:e,props:{":artifactLinks":aU,":authors":aV,":venue":aW,thumbnail:aX,title:aY,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aZ,":authors":a_,":venue":a$,thumbnail:ba,title:bb,type:u},children:[]},{type:a,tag:e,props:{":artifactLinks":bc,":authors":bd,":venue":be,thumbnail:bf,title:bg,type:u,":hideBottomBorder":bh},children:[]},{type:a,tag:g,props:{id:F},children:[{type:b,value:G}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bi}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bj},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bk}]},{type:a,tag:c,props:{},children:[{type:b,value:bl}]}]}]}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bm}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bn}]},{type:a,tag:c,props:{},children:[{type:b,value:bo}]},{type:a,tag:c,props:{},children:[{type:b,value:bp}]},{type:a,tag:c,props:{},children:[{type:b,value:bq}]},{type:a,tag:c,props:{},children:[{type:b,value:br}]},{type:a,tag:c,props:{},children:[{type:b,value:bs}]}]},{type:a,tag:g,props:{id:H},children:[{type:b,value:I}]},{type:a,tag:o,props:{icon:bt,url:bu},children:[{type:a,tag:d,props:{},children:[{type:b,value:bv}]}]},{type:a,tag:o,props:{icon:bw,url:bx},children:[{type:a,tag:d,props:{},children:[{type:b,value:by}]}]},{type:a,tag:o,props:{icon:bz,url:bA},children:[{type:a,tag:d,props:{},children:[{type:b,value:bB}]}]},{type:a,tag:o,props:{icon:bC,url:bD},children:[{type:a,tag:d,props:{},children:[{type:b,value:bE}]}]}]},hideTitle:k,disableFancyImage:k,body:{type:w,children:[{type:a,tag:N,props:{},children:[]},{type:a,tag:g,props:{id:x},children:[{type:b,value:y}]},{type:a,tag:d,props:{},children:[{type:b,value:O},{type:a,tag:h,props:{href:P,rel:[i]},children:[{type:b,value:Q}]},{type:b,value:R},{type:a,tag:h,props:{href:S,rel:[i]},children:[{type:b,value:T}]},{type:b,value:U},{type:a,tag:h,props:{href:V,rel:[i]},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:h,props:{href:Y,rel:[i]},children:[{type:b,value:Z}]},{type:b,value:_},{type:a,tag:h,props:{href:$,rel:[i]},children:[{type:b,value:aa}]},{type:b,value:ab},{type:a,tag:h,props:{href:ac,rel:[i]},children:[{type:b,value:ad}]},{type:b,value:ae}]},{type:a,tag:g,props:{id:z},children:[{type:b,value:A}]},{type:a,tag:af,props:{},children:[]},{type:a,tag:g,props:{id:B},children:[{type:b,value:C}]},{type:a,tag:s,props:{icon:ag},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:ah}]},{type:a,tag:n,props:{},children:[]},{type:b,value:ai},{type:a,tag:n,props:{},children:[]},{type:b,value:aj}]}]},{type:a,tag:s,props:{icon:ak},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:al}]},{type:a,tag:n,props:{},children:[]},{type:b,value:am},{type:a,tag:n,props:{},children:[]},{type:b,value:an}]}]},{type:a,tag:g,props:{id:D},children:[{type:b,value:E}]},{type:a,tag:e,props:{":artifactLinks":ao,":authors":ap,":venue":aq,thumbnail:ar,title:as,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":at,":authors":au,":venue":av,thumbnail:aw,title:ax,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":ay,":authors":az,":venue":t,thumbnail:aA,title:aB,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aC,":authors":aD,":venue":t,thumbnail:aE,title:aF,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aG,":authors":aH,":venue":aI,thumbnail:aJ,title:aK,type:j},children:[{type:a,tag:d,props:{},children:[{type:a,tag:aL,props:{className:[aM]},children:[{type:b,value:aN}]}]}]},{type:a,tag:e,props:{":artifactLinks":aO,":authors":aP,":venue":aQ,thumbnail:aR,title:aS,type:aT},children:[]},{type:a,tag:e,props:{":artifactLinks":aU,":authors":aV,":venue":aW,thumbnail:aX,title:aY,type:j},children:[]},{type:a,tag:e,props:{":artifactLinks":aZ,":authors":a_,":venue":a$,thumbnail:ba,title:bb,type:u},children:[]},{type:a,tag:e,props:{":artifactLinks":bc,":authors":bd,":venue":be,thumbnail:bf,title:bg,type:u,":hideBottomBorder":bh},children:[]},{type:a,tag:g,props:{id:F},children:[{type:b,value:G}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bi}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bj},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bk}]},{type:a,tag:c,props:{},children:[{type:b,value:bl}]}]}]}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bm}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bn}]},{type:a,tag:c,props:{},children:[{type:b,value:bo}]},{type:a,tag:c,props:{},children:[{type:b,value:bp}]},{type:a,tag:c,props:{},children:[{type:b,value:bq}]},{type:a,tag:c,props:{},children:[{type:b,value:br}]},{type:a,tag:c,props:{},children:[{type:b,value:bs}]}]},{type:a,tag:g,props:{id:H},children:[{type:b,value:I}]},{type:a,tag:o,props:{icon:bt,url:bu},children:[{type:a,tag:d,props:{},children:[{type:b,value:bv}]}]},{type:a,tag:o,props:{icon:bw,url:bx},children:[{type:a,tag:d,props:{},children:[{type:b,value:by}]}]},{type:a,tag:o,props:{icon:bz,url:bA},children:[{type:a,tag:d,props:{},children:[{type:b,value:bB}]}]},{type:a,tag:o,props:{icon:bC,url:bD},children:[{type:a,tag:d,props:{},children:[{type:b,value:bE}]}]}],toc:{title:m,searchDepth:p,depth:p,links:[{id:x,depth:p,text:y},{id:z,depth:p,text:A},{id:B,depth:p,text:C},{id:D,depth:p,text:E},{id:F,depth:p,text:G},{id:H,depth:p,text:I}]}},_type:bF,_id:"content:index.md",_source:bG,_file:"index.md",_extension:bH,layout:r}},"$sdd-surrounds":{"/":[null,{_path:bI,_dir:m,_draft:l,_partial:l,_locale:L,_empty:l,title:J,description:m,excerpt:{type:w,children:[{type:a,tag:"markdown-header",props:{subtitle:"üì¢ Latest: I'm a Ph.D. candidate now!",title:J},children:[]},{type:a,tag:d,props:{},children:[{type:a,tag:"img",props:{alt:m,src:"\u002Fassets\u002Fimg\u002Fme-news-google.png"},children:[]}]},{type:a,tag:q,props:{},children:[{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"05\u002F2023"}]},{type:b,value:" üéâ RFUniverse accepted by RSS 2023 Demo Track!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"02\u002F2023"}]},{type:b,value:" üéâ 2 papers accepted by CVPR 2023!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"10\u002F2022"}]},{type:b,value:" üéâ RCareWorld won the RoboCup Best Paper Award!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"09\u002F2022"}]},{type:b,value:" üéâ Received IROS-SDC Travel Award!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"08\u002F2022"}]},{type:b,value:" ‚ú® Starting my research journey as a PhD student!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"07\u002F2022"}]},{type:b,value:" üéâ RCareWorld accepted by IROS 2022!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"07\u002F2021"}]},{type:b,value:" üéâ H2O accepted by ICCV 2022!"}]}]}]},leadingImage:"me-news-google.png",disableFancyImage:k,_type:bF,_id:"content:news.md",_source:bG,_file:"news.md",_extension:bH}]},"$sdd-globals":{},"$sdd-navigation":[{title:M,_path:v},{title:J,_path:bI},{title:"Project",_path:"\u002Fproject",children:[{title:2048,_path:"\u002Fproject\u002F2048",layout:r},{title:"Deep Spectrum Feature Representations for Speech Emotion Recognition",_path:"\u002Fproject\u002Fdeep-spectrum",layout:r},{title:"LitAR: Visually Coherent Lighting for Mobile Augmented Reality",_path:"\u002Fproject\u002Flitar",layout:r},{title:"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",_path:"\u002Fproject\u002Fpoint-ar",layout:r},{title:"Privacy-preserving Reflection Rendering for Augmented Reality",_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:r},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:r}],layout:"cards"},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:k,config:{public:{content:{locales:[],integrity:1695236348810,experimental:{stripQueryParameters:l,clientDB:l},api:{baseURL:"\u002Fapi\u002F_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:m,documentDriven:{page:k,navigation:k,surround:k,globals:{},layoutFallbacks:["theme"],injectPage:k},anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:v,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:m}},prerenderedAt:void 0}}("element","text","li","p","publication-row","strong","h2","a","nofollow","conference",true,false,"","br","contact-item",2,"ul","default","experience-row","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"The IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition\"}","preprint","\u002F","root","about-me","üê± About Me","news","üì∞ News","experiences","ü•∑ Experiences","publications","üìÑ Publications","Ô∏è-services-and-awards","‚ù§Ô∏è Services and Awards","contacts","üìß Contacts","News","system","en","Home","index-header","My name is Ruolin Ye. I am a second-year Ph.D. student at Cornell University supervised by ","https:\u002F\u002Fsites.google.com\u002Fsite\u002Ftapomayukh","Prof. Tapomayukh Bhattacharjee",". Before that, I worked as an intern at ZenusTech supervised by ","https:\u002F\u002Fscholar.google.com\u002Fcitations?hl=en&user=SU6DkyYAAAAJ&view_op=list_works&sortby=pubdate","Dr. Xinxin Zhang",". I worked with ","https:\u002F\u002Fwww.mvig.org\u002F","Prof. Cewu Lu",", in MVIG Lab during my undergrad at Shanghai Jiao Tong University.\nMy research interest includes human-robot collaboration and simulation.\nIf you find any research interest we may share, or some intersection on projects I am working on, please feel free to drop me an Email. I am always open to collaboration.\nIn my spare time, I enjoy ","https:\u002F\u002Fwww.instagram.com\u002Fp\u002FCmf3pXtOFh1\u002F?utm_source=ig_web_copy_link","sketching",", ","https:\u002F\u002Fwww.instagram.com\u002Fp\u002FCRWg7z9grr0\u002F","watching musicals",", and making ","https:\u002F\u002Fwww.instagram.com\u002Fp\u002FCPifY_Vg7VY\u002F","cocktails",".","short-news","cornell.png","Cornell University, Ithaca, NY","\nPh.D. Student in Computer Science","\nAug 2022 - Present","sjtu.png","Shanghai Jiao Tong University, Shanghai, China","\nBachelor of Engineering in Information Engineering","\nSep 2018 - Aug 2022","{\"Paper (Coming soon)\":null}","[\"Ruolin Ye\",\"Yifei Hu\",\"Yuhan (Anjelica) Bian\",\"Luke Kulm\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"In submission\",\"year\":2023,\"name\":\"In submission\"}","peeling.png","MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop","{\"Paper\":null}","[\"Wenqiang Xu\",\"Wenxin Du\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV (Oral)\",\"year\":2023,\"name\":\"International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FCVPR2023\u002Fpapers\u002FXu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Fvtaco\u002F\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fjeffsonyu\u002FVTacO\",\"Dataset\":\"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Frobotflow\u002Fvtaco\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu\"]","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FCVPR2023\u002Fpapers\u002FXue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"Website\":\"https:\u002F\u002Fgarment-tracking.robotflow.ai\u002F\",\"Dataset\":\"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Frobotflow\u002Fvr-folding\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fxiaoxiaoxh\u002FGarmentTracking\"}","[\"Han Xue*\",\"Wenqiang Xu*\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","garmentTracking.png","GarmentTracking: Category-Level Garment Pose Tracking","{\"Paper\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28\u002Fview\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fempriselab\u002FRCareWorld\",\"Website\":\"https:\u002F\u002Femprise.cs.cornell.edu\u002Frcareworld\u002F\",\"Presentation\":\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=mNy1cloWrP0\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Haoyuan Fu\",\"Rajat Kumar Jenamani\",\"Vy Nguyen\",\"Cewu Lu\",\"Katherine Dimitropoulou\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2022,\"name\":\"IEEE\u002FRSJ International Conference on Intelligent Robots and Systems\"}","rcareworld.png","RCareWorld: A Human-centric Simulation World for Caregiving Robots","span","text-red-700","Best RoboCup paper (Winner). Best paper\u002Fbest student paper (Finalist).","{\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Frfuniverse\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fmvig-robotflow\u002Fpyrfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Zhenjun Yu\",\"Jieyi Zhang\",\"Yongxi Huang\",\"Cewu Lu\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics Science and Systems\"}","rfuniverse.png","RFUniverse: A Multiphysics Simulation Platform for Embodied AI","insubmission","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FICCV2021\u002Fpapers\u002FYe_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf\",\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Fhandover-h2o\u002Fhome\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Zhendong Xue\",\"Tutian Tang\",\"Yanfeng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV\",\"year\":2021,\"name\":\"International Conference on Computer Vision\"}","h2o.png","H2O: A Benchmark for Visual Human-human Object Handover Analysis","{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2012.01050.pdf\",\"Code\":\"https:\u002F\u002Fgithub.com\u002FYoruCathy\u002FUSDSeg-FCOS\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Lixin Yang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2020,\"name\":\"Preprint\"}","usd-seg.png","Learning Universal Shape Dictionary for Realtime Instance Segmentation","{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2106.03382.pdf\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2021,\"name\":\"Preprint\"}","contour.png","ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass","true","Academic services","Reviewer","Conferences: ICCV 2023, CVPR 2022&2023, ECCV 2022, IROS 2022, ICRA 2023","Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics","Awards","IROS-SDC Travel Award, IROS 2022","RoboCup Best Paper Award, IROS 2022","Best Paper\u002FStudent Paper Finalist, IROS 2022","Bosch AIoT Scholarship, 2022","Queer in AI Grad Admissions Fee Aid, 2022","Honorable Mention, MCM\u002FICM Mathematical Contest 2020&2021","email","mailto:ry273@cornell.edu","Email","github","https:\u002F\u002Fgithub.com\u002FYoruCathy","GitHub","twitter","https:\u002F\u002Ftwitter.com\u002FNekovowo","Twitter","wechat","https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ\u002Fview?usp=sharing","Wechat","markdown","content","md","\u002Fnews")))}</script><script type="module" src="/_nuxt/entry.d2d75a21.js" crossorigin></script><script type="module" src="/_nuxt/document-driven.b74b1f73.js" crossorigin></script><script type="module" src="/_nuxt/default.e22e54d6.js" crossorigin></script><script type="module" src="/_nuxt/Navigator.eb2e574b.js" crossorigin></script><script type="module" src="/_nuxt/ContentDoc.276c8668.js" crossorigin></script><script type="module" src="/_nuxt/ContentQuery.790c7fb2.js" crossorigin></script><script type="module" src="/_nuxt/Footer.b3ba153d.js" crossorigin></script><script type="module" src="/_nuxt/ContentRenderer.a86455b3.js" crossorigin></script><script type="module" src="/_nuxt/ContentRendererMarkdown.a9b16923.js" crossorigin></script><script type="module" src="/_nuxt/IndexHeader.7e90a6db.js" crossorigin></script><script type="module" src="/_nuxt/ProseH2.764d77ad.js" crossorigin></script><script type="module" src="/_nuxt/ProseP.87d899df.js" crossorigin></script><script type="module" src="/_nuxt/ProseA.6b6e4844.js" crossorigin></script><script type="module" src="/_nuxt/ShortNews.a166ade8.js" crossorigin></script><script type="module" src="/_nuxt/ExperienceRow.a98e994c.js" crossorigin></script><script type="module" src="/_nuxt/ContentSlot.127fe4c8.js" crossorigin></script><script type="module" src="/_nuxt/ProseStrong.8a73ad73.js" crossorigin></script><script type="module" src="/_nuxt/PublicationRow.a587cb54.js" crossorigin></script><script type="module" src="/_nuxt/ProseUl.20448ab5.js" crossorigin></script><script type="module" src="/_nuxt/ProseLi.11557dd1.js" crossorigin></script><script type="module" src="/_nuxt/ContactItem.06b7bfdc.js" crossorigin></script><script type="module" src="/_nuxt/MarkdownHeader.d40cf4c4.js" crossorigin></script><script type="module" src="/_nuxt/ProseImg.c55f625c.js" crossorigin></script></body>
</html>