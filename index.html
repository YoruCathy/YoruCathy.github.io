<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Home - Ruolin Ye</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üê±</text></svg>">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css"><link rel="modulepreload" href="/_payload.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.b332fe6a.js"><link rel="preload" as="style" href="/_nuxt/entry.d049ffb0.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.b5e4cc40.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.127af5b9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.5cdc08e8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.ab014f99.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_commonjsHelpers.fed2a411.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.9e7f8d34.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/layout.a3516e1a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.4fd8b078.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.2b5ba21a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.cd565466.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.c53894d2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.315de8ce.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.9660fd5e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.6c741254.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.77d891a4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.a1a6add7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.07c4e70b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.96887212.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.74bd291c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.bd8b597e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentSlot.8e9ec607.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.9f568dc6.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.78dd8d4d.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.bffbb707.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.10e256fe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.923cea87.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentNavigation.91759972.js"><link rel="prefetch" as="style" href="/_nuxt/ContentNavigation.8ff1cb40.css"><link rel="prefetch" as="style" href="/_nuxt/IndexHeader.6f25759d.css"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.754395c0.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Markdown.d33b4249.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ProseCode.a33059d8.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.50dc01f6.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.61c97a20.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/web-socket.2b14c831.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.24faff12.js"><link rel="stylesheet" href="/_nuxt/entry.d049ffb0.css"><style>body{background-color:rgb(250 250 249/var(--tw-bg-opacity))}.dark body,body{--tw-bg-opacity:1}.dark body{background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear,color .1s linear}a:hover{color:#fc639b!important;opacity:.8}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><style>body{background-color:#fff8fb}footer{background-color:#efdfe6!important}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><!--[--><div class="document-driven-page"><!--[--><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="https://drive.google.com/file/d/1ymWkcZ9Qv3MOCyV754qzYLHcJ6Et03Yh/view?usp=sharing"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="https://drive.google.com/file/d/1ymWkcZ9Qv3MOCyV754qzYLHcJ6Et03Yh/view?usp=sharing"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">CV</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-8 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-[#e4c7d3] dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Ruolin Ye</p><p class="w-full text-xl prose dark:prose-invert m-0 text-left"> (She/Her) <br> First-year Ph.D. Student in Computer Science<a href="https://emprise.cs.cornell.edu">@EmPRISELab</a>, Cornell University<br> Research: Human-robot interaction, Simulation </p><p class="mt-4 w-full m-0"><span class="m-0"><a href="mailto:ry273@cornell.edu"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YoruCathy"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://twitter.com/nekovowo"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a><a href="https://scholar.google.com/citations?user=fCy8NOUAAAAJ&amp;hl=en"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/google-scholar.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/cathy.png" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-100" src="/assets/img/cathy-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-[#efdfe6] dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/cathy.png" alt=""></div></div></div></div></div><h2 id="about-me"><a href="#about-me"><!--[-->üê± About Me<!--]--></a></h2><p><!--[-->My name is Ruolin Ye. I am a second-year Ph.D. student at Cornell University supervised by <a href="https://sites.google.com/site/tapomayukh" rel="nofollow"><!--[-->Prof. Tapomayukh Bhattacharjee<!--]--></a>. I worked with <a href="https://www.mvig.org/" rel="nofollow"><!--[-->Prof. Cewu Lu<!--]--></a>, in MVIG Lab during my undergrad at Shanghai Jiao Tong University.<!--]--></p><p><!--[-->My broad research interest is robotic caregiving, and I am especially interested in the task of transferring. I study how to coordinate multiple instrumented assistive devices to complete this task. I am also interested in simulation. I am leading the <a href="https://emprise.cs.cornell.edu/rcareworld/" rel="nofollow"><!--[-->RCareWorld<!--]--></a> simulation project.<!--]--></p><p><!--[-->In my spare time, I volunteer at <a href="https://www.wonderfulwheelchairs.info/home" rel="nofollow"><!--[-->Wonderful Wheelchairs<!--]--></a>, a local non-profit organization that repairs and sells assistive devices to people with a low cost. I enjoy horseback riding, sketching, making cocktails, and spending time with my cat.<!--]--></p><h2 id="experiences"><a href="#experiences"><!--[-->ü•∑ Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-cornell.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/cornell.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Cornell University, Ithaca, NY<!--]--></strong><br>
Ph.D. Student in Computer Science<br>
Aug 2022 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-sjtu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/sjtu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Shanghai Jiao Tong University, Shanghai, China<!--]--></strong><br>
Bachelor of Engineering in Information Engineering<br>
Sep 2018 - Aug 2022<!--]--></p><!--]--><!--]--></div></div><h2 id="publications"><a href="#publications"><!--[-->üìÑ Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IROS&#39;24</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2410.10017">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://emprise.cs.cornell.edu/repeat/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/repeat.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Nayoung Ha*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Ziang Liu</span><span>,¬†</span></span><span><span class="">Shubhangi Sinha</span><span>,¬†</span></span><span><span class="">Tapomayukh Bhattacharjee</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">International Conference on Intelligent Robots and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICRA&#39;24</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://ieeexplore.ieee.org/abstract/document/10610050">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://emprise.cs.cornell.edu/morpheus/">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/peeling.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yifei Hu</span><span>,¬†</span></span><span><span class="">Yuhan (Anjelica) Bian</span><span>,¬†</span></span><span><span class="">Luke Kulm</span><span>,¬†</span></span><span><span class="">Tapomayukh Bhattacharjee</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE International Conference on Robotics and Automation</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICCV (Oral)&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf">Paper</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/clothpose.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yan-feng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">International Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/vtaco/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/jeffsonyu/VTacO">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://huggingface.co/datasets/robotflow/vtaco">Dataset</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Visual-Tactile Sensing for In-Hand Object Reconstruction</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/vtaco.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Zhenjun Yu*</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Siqiong Yao</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">The IEEE/CVF Conference on Computer Vision and Pattern Recognition</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">CVPR&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://garment-tracking.robotflow.ai/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://huggingface.co/datasets/robotflow/vr-folding">Dataset</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/xiaoxiaoxh/GarmentTracking">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">GarmentTracking: Category-Level Garment Pose Tracking</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/garmentTracking.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Han Xue*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Jieyi Zhang</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">The IEEE/CVF Conference on Computer Vision and Pattern Recognition</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IROS&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28/view">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/empriselab/RCareWorld">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://emprise.cs.cornell.edu/rcareworld/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.youtube.com/watch?v=mNy1cloWrP0">Presentation</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">RCareWorld: A Human-centric Simulation World for Caregiving Robots</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rcareworld.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Haoyuan Fu</span><span>,¬†</span></span><span><span class="">Rajat Kumar Jenamani</span><span>,¬†</span></span><span><span class="">Vy Nguyen</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>,¬†</span></span><span><span class="">Katherine Dimitropoulou</span><span>,¬†</span></span><span><span class="">Tapomayukh Bhattacharjee</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE/RSJ International Conference on Intelligent Robots and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-700">Best RoboCup paper (Winner). Best paper/best student paper (Finalist).</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="insubmission"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">RSS&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/rfuniverse">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/mvig-robotflow/pyrfuniverse">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">RFUniverse: A Multiphysics Simulation Platform for Embodied AI</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/rfuniverse.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Haoyuan Fu*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Han Xue</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yutong Li</span><span>,¬†</span></span><span><span class="">Wenxin Du</span><span>,¬†</span></span><span><span class="">Zhenjun Yu</span><span>,¬†</span></span><span><span class="">Jieyi Zhang</span><span>,¬†</span></span><span><span class="">Yongxi Huang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Robotics Science and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ICCV&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://sites.google.com/view/handover-h2o/home">Website</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">H2O: A Benchmark for Visual Human-human Object Handover Analysis</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/h2o.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Ruolin Ye*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="">Zhendong Xue</span><span>,¬†</span></span><span><span class="">Tutian Tang</span><span>,¬†</span></span><span><span class="">Yanfeng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">International Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="preprint"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">arXiv&#39;20</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2012.01050.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/YoruCathy/USDSeg-FCOS">Code</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Learning Universal Shape Dictionary for Realtime Instance Segmentation</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/usd-seg.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Tutian Tang*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Lixin Yang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Preprint</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8" type="preprint"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">arXiv&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2106.03382.pdf">Paper</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/contour.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Tutian Tang*</span><span>,¬†</span></span><span><span class="">Wenqiang Xu*</span><span>,¬†</span></span><span><span class="font-bold dark:text-white underline">Ruolin Ye</span><span>,¬†</span></span><span><span class="">Yan-feng Wang</span><span>,¬†</span></span><span><span class="">Cewu Lu</span><span>¬†</span></span><!--]--></div><div class="text-gray-500 text-sm">Preprint</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><h2 id="Ô∏è-services-and-awards"><a href="#Ô∏è-services-and-awards"><!--[-->‚ù§Ô∏è Services and Awards<!--]--></a></h2><p><!--[--><strong><!--[-->Academic services<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->Reviewer<ul><!--[--><li><!--[-->Conferences: ICCV 2023, CVPR 2022&amp;2023, ECCV 2022, IROS 2022-2024, ICRA 2023-2024, HRI 2025<!--]--></li><li><!--[-->Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics, T-RO<!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->Awards<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->Outstading teaching assistant, Cornell 2024<!--]--></li><li><!--[-->IROS-SDC Travel Award, IROS 2022<!--]--></li><li><!--[-->RoboCup Best Paper Award, IROS 2022<!--]--></li><li><!--[-->Best Paper/Student Paper Finalist, IROS 2022<!--]--></li><li><!--[-->Bosch AIoT Scholarship, 2022<!--]--></li><li><!--[-->Queer in AI Grad Admissions Fee Aid, 2022<!--]--></li><li><!--[-->Honorable Mention, MCM/ICM Mathematical Contest 2020&amp;2021<!--]--></li><!--]--></ul><h2 id="contacts"><a href="#contacts"><!--[-->üìß Contacts<!--]--></a></h2><span><a href="mailto:ry273@cornell.edu" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/YoruCathy" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/Nekovowo" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span><span><a href="https://drive.google.com/file/d/1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ/view?usp=sharing" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/wechat.svg" alt=""><!--[-->Wechat<!--]--></a></span></div><!--]--></article><footer class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> Âè∂Ëã•Áê≥ | Ruolin <br> CS Ph.D. Student <a href="https://emprise.cs.cornell.edu">EmPRISE Lab, Cornell University</a> <br> Research Interests: Human robot interaction, Intelligent devices, Simulation </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:ry273@cornell.edu">E-Mail</a> <br><a href="https://github.com/YoruCathy">GitHub</a> <br><a href="https://twitter.com/Nekovowo">Twitter</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> ¬© <a href="/">Ruolin Ye</a> 2024. Last updated: 11/24/2024. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template made by Yiqin Zhao</a>. </p></div></div></footer><!--]--><!--]--></div><!--]--><!--]--></div><script type="module">import p from "/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb,bc,bd,be,bf,bg,bh,bi,bj,bk,bl,bm,bn,bo,bp,bq,br,bs,bt,bu,bv,bw,bx,by,bz,bA,bB,bC,bD,bE,bF,bG,bH){return {state:{"$scolor-mode":{preference:I,value:I,unknown:i,forced:j},"$sdd-pages":{"/":{_path:v,_dir:k,_draft:j,_partial:j,_locale:J,_empty:j,title:K,description:k,excerpt:{type:w,children:[{type:a,tag:L,props:{},children:[]},{type:a,tag:h,props:{id:x},children:[{type:b,value:y}]},{type:a,tag:d,props:{},children:[{type:b,value:M},{type:a,tag:l,props:{href:N,rel:[m]},children:[{type:b,value:O}]},{type:b,value:P},{type:a,tag:l,props:{href:Q,rel:[m]},children:[{type:b,value:R}]},{type:b,value:S}]},{type:a,tag:d,props:{},children:[{type:b,value:T},{type:a,tag:l,props:{href:U,rel:[m]},children:[{type:b,value:V}]},{type:b,value:W}]},{type:a,tag:d,props:{},children:[{type:b,value:X},{type:a,tag:l,props:{href:Y,rel:[m]},children:[{type:b,value:Z}]},{type:b,value:_}]},{type:a,tag:h,props:{id:z},children:[{type:b,value:A}]},{type:a,tag:s,props:{icon:$},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:aa}]},{type:a,tag:n,props:{},children:[]},{type:b,value:ab},{type:a,tag:n,props:{},children:[]},{type:b,value:ac}]}]},{type:a,tag:s,props:{icon:ad},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:ae}]},{type:a,tag:n,props:{},children:[]},{type:b,value:af},{type:a,tag:n,props:{},children:[]},{type:b,value:ag}]}]},{type:a,tag:h,props:{id:B},children:[{type:b,value:C}]},{type:a,tag:e,props:{":artifactLinks":ah,":authors":ai,":venue":aj,thumbnail:ak,title:al,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":am,":authors":an,":venue":ao,thumbnail:ap,title:aq,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":ar,":authors":as,":venue":at,thumbnail:au,title:av,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aw,":authors":ax,":venue":t,thumbnail:ay,title:az,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aA,":authors":aB,":venue":t,thumbnail:aC,title:aD,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aE,":authors":aF,":venue":aG,thumbnail:aH,title:aI,type:g},children:[{type:a,tag:d,props:{},children:[{type:a,tag:aJ,props:{className:[aK]},children:[{type:b,value:aL}]}]}]},{type:a,tag:e,props:{":artifactLinks":aM,":authors":aN,":venue":aO,thumbnail:aP,title:aQ,type:aR},children:[]},{type:a,tag:e,props:{":artifactLinks":aS,":authors":aT,":venue":aU,thumbnail:aV,title:aW,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aX,":authors":aY,":venue":aZ,thumbnail:a_,title:a$,type:u},children:[]},{type:a,tag:e,props:{":artifactLinks":ba,":authors":bb,":venue":bc,thumbnail:bd,title:be,type:u,":hideBottomBorder":bf},children:[]},{type:a,tag:h,props:{id:D},children:[{type:b,value:E}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bg}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bh},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bi}]},{type:a,tag:c,props:{},children:[{type:b,value:bj}]}]}]}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bk}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bl}]},{type:a,tag:c,props:{},children:[{type:b,value:bm}]},{type:a,tag:c,props:{},children:[{type:b,value:bn}]},{type:a,tag:c,props:{},children:[{type:b,value:bo}]},{type:a,tag:c,props:{},children:[{type:b,value:bp}]},{type:a,tag:c,props:{},children:[{type:b,value:bq}]},{type:a,tag:c,props:{},children:[{type:b,value:br}]}]},{type:a,tag:h,props:{id:F},children:[{type:b,value:G}]},{type:a,tag:o,props:{icon:bs,url:bt},children:[{type:a,tag:d,props:{},children:[{type:b,value:bu}]}]},{type:a,tag:o,props:{icon:bv,url:bw},children:[{type:a,tag:d,props:{},children:[{type:b,value:bx}]}]},{type:a,tag:o,props:{icon:by,url:bz},children:[{type:a,tag:d,props:{},children:[{type:b,value:bA}]}]},{type:a,tag:o,props:{icon:bB,url:bC},children:[{type:a,tag:d,props:{},children:[{type:b,value:bD}]}]}]},hideTitle:i,disableFancyImage:i,body:{type:w,children:[{type:a,tag:L,props:{},children:[]},{type:a,tag:h,props:{id:x},children:[{type:b,value:y}]},{type:a,tag:d,props:{},children:[{type:b,value:M},{type:a,tag:l,props:{href:N,rel:[m]},children:[{type:b,value:O}]},{type:b,value:P},{type:a,tag:l,props:{href:Q,rel:[m]},children:[{type:b,value:R}]},{type:b,value:S}]},{type:a,tag:d,props:{},children:[{type:b,value:T},{type:a,tag:l,props:{href:U,rel:[m]},children:[{type:b,value:V}]},{type:b,value:W}]},{type:a,tag:d,props:{},children:[{type:b,value:X},{type:a,tag:l,props:{href:Y,rel:[m]},children:[{type:b,value:Z}]},{type:b,value:_}]},{type:a,tag:h,props:{id:z},children:[{type:b,value:A}]},{type:a,tag:s,props:{icon:$},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:aa}]},{type:a,tag:n,props:{},children:[]},{type:b,value:ab},{type:a,tag:n,props:{},children:[]},{type:b,value:ac}]}]},{type:a,tag:s,props:{icon:ad},children:[{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:ae}]},{type:a,tag:n,props:{},children:[]},{type:b,value:af},{type:a,tag:n,props:{},children:[]},{type:b,value:ag}]}]},{type:a,tag:h,props:{id:B},children:[{type:b,value:C}]},{type:a,tag:e,props:{":artifactLinks":ah,":authors":ai,":venue":aj,thumbnail:ak,title:al,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":am,":authors":an,":venue":ao,thumbnail:ap,title:aq,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":ar,":authors":as,":venue":at,thumbnail:au,title:av,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aw,":authors":ax,":venue":t,thumbnail:ay,title:az,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aA,":authors":aB,":venue":t,thumbnail:aC,title:aD,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aE,":authors":aF,":venue":aG,thumbnail:aH,title:aI,type:g},children:[{type:a,tag:d,props:{},children:[{type:a,tag:aJ,props:{className:[aK]},children:[{type:b,value:aL}]}]}]},{type:a,tag:e,props:{":artifactLinks":aM,":authors":aN,":venue":aO,thumbnail:aP,title:aQ,type:aR},children:[]},{type:a,tag:e,props:{":artifactLinks":aS,":authors":aT,":venue":aU,thumbnail:aV,title:aW,type:g},children:[]},{type:a,tag:e,props:{":artifactLinks":aX,":authors":aY,":venue":aZ,thumbnail:a_,title:a$,type:u},children:[]},{type:a,tag:e,props:{":artifactLinks":ba,":authors":bb,":venue":bc,thumbnail:bd,title:be,type:u,":hideBottomBorder":bf},children:[]},{type:a,tag:h,props:{id:D},children:[{type:b,value:E}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bg}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bh},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bi}]},{type:a,tag:c,props:{},children:[{type:b,value:bj}]}]}]}]},{type:a,tag:d,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:bk}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:bl}]},{type:a,tag:c,props:{},children:[{type:b,value:bm}]},{type:a,tag:c,props:{},children:[{type:b,value:bn}]},{type:a,tag:c,props:{},children:[{type:b,value:bo}]},{type:a,tag:c,props:{},children:[{type:b,value:bp}]},{type:a,tag:c,props:{},children:[{type:b,value:bq}]},{type:a,tag:c,props:{},children:[{type:b,value:br}]}]},{type:a,tag:h,props:{id:F},children:[{type:b,value:G}]},{type:a,tag:o,props:{icon:bs,url:bt},children:[{type:a,tag:d,props:{},children:[{type:b,value:bu}]}]},{type:a,tag:o,props:{icon:bv,url:bw},children:[{type:a,tag:d,props:{},children:[{type:b,value:bx}]}]},{type:a,tag:o,props:{icon:by,url:bz},children:[{type:a,tag:d,props:{},children:[{type:b,value:bA}]}]},{type:a,tag:o,props:{icon:bB,url:bC},children:[{type:a,tag:d,props:{},children:[{type:b,value:bD}]}]}],toc:{title:k,searchDepth:q,depth:q,links:[{id:x,depth:q,text:y},{id:z,depth:q,text:A},{id:B,depth:q,text:C},{id:D,depth:q,text:E},{id:F,depth:q,text:G}]}},_type:bE,_id:"content:index.md",_source:bF,_file:"index.md",_extension:bG,layout:r}},"$sdd-surrounds":{"/":[null,{_path:bH,_dir:k,_draft:j,_partial:j,_locale:J,_empty:j,title:H,description:k,excerpt:{type:w,children:[{type:a,tag:"markdown-header",props:{subtitle:"üì¢ Latest: I'm a Ph.D. candidate now!",title:H},children:[]},{type:a,tag:d,props:{},children:[{type:a,tag:"img",props:{alt:k,src:"\u002Fassets\u002Fimg\u002Fme-news-google.png"},children:[]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"05\u002F2023"}]},{type:b,value:" üéâ RFUniverse accepted by RSS 2023 Demo Track!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"02\u002F2023"}]},{type:b,value:" üéâ 2 papers accepted by CVPR 2023!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"10\u002F2022"}]},{type:b,value:" üéâ RCareWorld won the RoboCup Best Paper Award!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"09\u002F2022"}]},{type:b,value:" üéâ Received IROS-SDC Travel Award!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"08\u002F2022"}]},{type:b,value:" ‚ú® Starting my research journey as a PhD student!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"07\u002F2022"}]},{type:b,value:" üéâ RCareWorld accepted by IROS 2022!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{},children:[{type:b,value:"07\u002F2021"}]},{type:b,value:" üéâ H2O accepted by ICCV 2022!"}]}]}]},leadingImage:"me-news-google.png",disableFancyImage:i,_type:bE,_id:"content:news.md",_source:bF,_file:"news.md",_extension:bG}]},"$sdd-globals":{},"$sdd-navigation":[{title:K,_path:v},{title:H,_path:bH},{title:"Project",_path:"\u002Fproject",children:[{title:2048,_path:"\u002Fproject\u002F2048",layout:r},{title:"Deep Spectrum Feature Representations for Speech Emotion Recognition",_path:"\u002Fproject\u002Fdeep-spectrum",layout:r},{title:"LitAR: Visually Coherent Lighting for Mobile Augmented Reality",_path:"\u002Fproject\u002Flitar",layout:r},{title:"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",_path:"\u002Fproject\u002Fpoint-ar",layout:r},{title:"Privacy-preserving Reflection Rendering for Augmented Reality",_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:r},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:r}],layout:"cards"},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:i,config:{public:{content:{locales:[],integrity:1732470694687,experimental:{stripQueryParameters:j,clientDB:j},api:{baseURL:"\u002Fapi\u002F_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:k,documentDriven:{page:i,navigation:i,surround:i,globals:{},layoutFallbacks:["theme"],injectPage:i},anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:v,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:k}},prerenderedAt:void 0}}("element","text","li","p","publication-row","strong","conference","h2",true,false,"","a","nofollow","br","contact-item","ul",2,"default","experience-row","{\"acronym\":\"CVPR\",\"year\":2023,\"name\":\"The IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition\"}","preprint","\u002F","root","about-me","üê± About Me","experiences","ü•∑ Experiences","publications","üìÑ Publications","Ô∏è-services-and-awards","‚ù§Ô∏è Services and Awards","contacts","üìß Contacts","News","system","en","Home","index-header","My name is Ruolin Ye. I am a second-year Ph.D. student at Cornell University supervised by ","https:\u002F\u002Fsites.google.com\u002Fsite\u002Ftapomayukh","Prof. Tapomayukh Bhattacharjee",". I worked with ","https:\u002F\u002Fwww.mvig.org\u002F","Prof. Cewu Lu",", in MVIG Lab during my undergrad at Shanghai Jiao Tong University.","My broad research interest is robotic caregiving, and I am especially interested in the task of transferring. I study how to coordinate multiple instrumented assistive devices to complete this task. I am also interested in simulation. I am leading the ","https:\u002F\u002Femprise.cs.cornell.edu\u002Frcareworld\u002F","RCareWorld"," simulation project.","In my spare time, I volunteer at ","https:\u002F\u002Fwww.wonderfulwheelchairs.info\u002Fhome","Wonderful Wheelchairs",", a local non-profit organization that repairs and sells assistive devices to people with a low cost. I enjoy horseback riding, sketching, making cocktails, and spending time with my cat.","cornell.png","Cornell University, Ithaca, NY","\nPh.D. Student in Computer Science","\nAug 2022 - Present","sjtu.png","Shanghai Jiao Tong University, Shanghai, China","\nBachelor of Engineering in Information Engineering","\nSep 2018 - Aug 2022","{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2410.10017\",\"Website\":\"https:\u002F\u002Femprise.cs.cornell.edu\u002Frepeat\u002F\"}","[\"Nayoung Ha*\",\"Ruolin Ye*\",\"Ziang Liu\",\"Shubhangi Sinha\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2024,\"name\":\"International Conference on Intelligent Robots and Systems\"}","repeat.png","REPeat: A Real2Sim2Real Approach for Pre-acquisition of Soft Food Items in Robot-assisted Feeding","{\"Paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fabstract\u002Fdocument\u002F10610050\",\"Website\":\"https:\u002F\u002Femprise.cs.cornell.edu\u002Fmorpheus\u002F\"}","[\"Ruolin Ye\",\"Yifei Hu\",\"Yuhan (Anjelica) Bian\",\"Luke Kulm\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"ICRA\",\"year\":2024,\"name\":\"IEEE International Conference on Robotics and Automation\"}","peeling.png","MORPHeus: a Multimodal One-armed Robot-assisted Peeling system with Human Users in-the-loop","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FICCV2023\u002Fpapers\u002FXu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf\"}","[\"Wenqiang Xu\",\"Wenxin Du\",\"Han Xue\",\"Yutong Li\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV (Oral)\",\"year\":2023,\"name\":\"International Conference on Computer Vision\"}","clothpose.png","ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FCVPR2023\u002Fpapers\u002FXu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf\",\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Fvtaco\u002F\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fjeffsonyu\u002FVTacO\",\"Dataset\":\"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Frobotflow\u002Fvtaco\"}","[\"Wenqiang Xu*\",\"Zhenjun Yu*\",\"Han Xue\",\"Ruolin Ye\",\"Siqiong Yao\",\"Cewu Lu\"]","vtaco.png","Visual-Tactile Sensing for In-Hand Object Reconstruction","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FCVPR2023\u002Fpapers\u002FXue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf\",\"Website\":\"https:\u002F\u002Fgarment-tracking.robotflow.ai\u002F\",\"Dataset\":\"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Frobotflow\u002Fvr-folding\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fxiaoxiaoxh\u002FGarmentTracking\"}","[\"Han Xue*\",\"Wenqiang Xu*\",\"Jieyi Zhang\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Ruolin Ye\",\"Cewu Lu\"]","garmentTracking.png","GarmentTracking: Category-Level Garment Pose Tracking","{\"Paper\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1k1OQ6xpr0G4DSw0lSFxrAYv5kO-a0M28\u002Fview\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fempriselab\u002FRCareWorld\",\"Website\":\"https:\u002F\u002Femprise.cs.cornell.edu\u002Frcareworld\u002F\",\"Presentation\":\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=mNy1cloWrP0\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Haoyuan Fu\",\"Rajat Kumar Jenamani\",\"Vy Nguyen\",\"Cewu Lu\",\"Katherine Dimitropoulou\",\"Tapomayukh Bhattacharjee\"]","{\"acronym\":\"IROS\",\"year\":2022,\"name\":\"IEEE\u002FRSJ International Conference on Intelligent Robots and Systems\"}","rcareworld.png","RCareWorld: A Human-centric Simulation World for Caregiving Robots","span","text-red-700","Best RoboCup paper (Winner). Best paper\u002Fbest student paper (Finalist).","{\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Frfuniverse\",\"Code\":\"https:\u002F\u002Fgithub.com\u002Fmvig-robotflow\u002Fpyrfuniverse\"}","[\"Haoyuan Fu*\",\"Wenqiang Xu*\",\"Ruolin Ye*\",\"Han Xue\",\"Tutian Tang\",\"Yutong Li\",\"Wenxin Du\",\"Zhenjun Yu\",\"Jieyi Zhang\",\"Yongxi Huang\",\"Cewu Lu\"]","{\"acronym\":\"RSS\",\"year\":2023,\"name\":\"Robotics Science and Systems\"}","rfuniverse.png","RFUniverse: A Multiphysics Simulation Platform for Embodied AI","insubmission","{\"Paper\":\"https:\u002F\u002Fopenaccess.thecvf.com\u002Fcontent\u002FICCV2021\u002Fpapers\u002FYe_H2O_A_Benchmark_for_Visual_Human-Human_Object_Handover_Analysis_ICCV_2021_paper.pdf\",\"Website\":\"https:\u002F\u002Fsites.google.com\u002Fview\u002Fhandover-h2o\u002Fhome\"}","[\"Ruolin Ye*\",\"Wenqiang Xu*\",\"Zhendong Xue\",\"Tutian Tang\",\"Yanfeng Wang\",\"Cewu Lu\"]","{\"acronym\":\"ICCV\",\"year\":2021,\"name\":\"International Conference on Computer Vision\"}","h2o.png","H2O: A Benchmark for Visual Human-human Object Handover Analysis","{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2012.01050.pdf\",\"Code\":\"https:\u002F\u002Fgithub.com\u002FYoruCathy\u002FUSDSeg-FCOS\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Lixin Yang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2020,\"name\":\"Preprint\"}","usd-seg.png","Learning Universal Shape Dictionary for Realtime Instance Segmentation","{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2106.03382.pdf\"}","[\"Tutian Tang*\",\"Wenqiang Xu*\",\"Ruolin Ye\",\"Yan-feng Wang\",\"Cewu Lu\"]","{\"acronym\":\"arXiv\",\"year\":2021,\"name\":\"Preprint\"}","contour.png","ContourRender: Detecting Arbitrary Contour Shape For Instance Segmentation In One Pass","true","Academic services","Reviewer","Conferences: ICCV 2023, CVPR 2022&2023, ECCV 2022, IROS 2022-2024, ICRA 2023-2024, HRI 2025","Jornals: Frontiers in Robotics and AI, Frontiers in Neurorobotics, T-RO","Awards","Outstading teaching assistant, Cornell 2024","IROS-SDC Travel Award, IROS 2022","RoboCup Best Paper Award, IROS 2022","Best Paper\u002FStudent Paper Finalist, IROS 2022","Bosch AIoT Scholarship, 2022","Queer in AI Grad Admissions Fee Aid, 2022","Honorable Mention, MCM\u002FICM Mathematical Contest 2020&2021","email","mailto:ry273@cornell.edu","Email","github","https:\u002F\u002Fgithub.com\u002FYoruCathy","GitHub","twitter","https:\u002F\u002Ftwitter.com\u002FNekovowo","Twitter","wechat","https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1ftw-1Aae2tOVMPGso8DssAn4DNUpGmaJ\u002Fview?usp=sharing","Wechat","markdown","content","md","\u002Fnews")))}</script><script type="module" src="/_nuxt/entry.b332fe6a.js" crossorigin></script><script type="module" src="/_nuxt/document-driven.b5e4cc40.js" crossorigin></script><script type="module" src="/_nuxt/default.2b5ba21a.js" crossorigin></script><script type="module" src="/_nuxt/Navigator.cd565466.js" crossorigin></script><script type="module" src="/_nuxt/ContentDoc.c53894d2.js" crossorigin></script><script type="module" src="/_nuxt/ContentQuery.315de8ce.js" crossorigin></script><script type="module" src="/_nuxt/Footer.6c741254.js" crossorigin></script><script type="module" src="/_nuxt/ContentRenderer.5cdc08e8.js" crossorigin></script><script type="module" src="/_nuxt/ContentRendererMarkdown.ab014f99.js" crossorigin></script><script type="module" src="/_nuxt/IndexHeader.77d891a4.js" crossorigin></script><script type="module" src="/_nuxt/ProseH2.07c4e70b.js" crossorigin></script><script type="module" src="/_nuxt/ProseP.96887212.js" crossorigin></script><script type="module" src="/_nuxt/ProseA.74bd291c.js" crossorigin></script><script type="module" src="/_nuxt/ExperienceRow.bd8b597e.js" crossorigin></script><script type="module" src="/_nuxt/ContentSlot.8e9ec607.js" crossorigin></script><script type="module" src="/_nuxt/ProseStrong.9f568dc6.js" crossorigin></script><script type="module" src="/_nuxt/PublicationRow.78dd8d4d.js" crossorigin></script><script type="module" src="/_nuxt/ProseUl.bffbb707.js" crossorigin></script><script type="module" src="/_nuxt/ProseLi.10e256fe.js" crossorigin></script><script type="module" src="/_nuxt/ContactItem.923cea87.js" crossorigin></script></body>
</html>